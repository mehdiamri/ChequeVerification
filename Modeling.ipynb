{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "696a3118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import skimage.io as sk\n",
    "from skimage import img_as_ubyte\n",
    "from skimage.io import imread\n",
    "from scipy import spatial\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, Lambda, MaxPooling2D, Conv2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.models import Sequential\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.cm as cm\n",
    "from scipy import ndimage\n",
    "from skimage.measure import regionprops\n",
    "from skimage import io\n",
    "from skimage.filters import threshold_otsu   # For finding the threshold for grayscale to binary conversion\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67360244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mehdi/Bureau/PI/newdata\n"
     ]
    }
   ],
   "source": [
    "CurrentWorkingDir = os.path.dirname(os.getcwd())\n",
    "CurrentWorkingDir = os.path.join(CurrentWorkingDir,\"PI/newdata\")\n",
    "print(CurrentWorkingDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb4536c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "GeniuneDirectory = os.path.join(CurrentWorkingDir,\"real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e13c33c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/mehdi/Bureau/PI/newdata/real/Real_014_09.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_009_18.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_015_09.PNG', '/home/mehdi/Bureau/PI/newdata/real/009009_002.png', '/home/mehdi/Bureau/PI/newdata/real/Real_004_05.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_006_09.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_006_21.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_004_11.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_001_18.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_003_01.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_006_12.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_012_04.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_016_01.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_001_21.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_006_16.PNG', '/home/mehdi/Bureau/PI/newdata/real/001001_003.png', '/home/mehdi/Bureau/PI/newdata/real/003003_001.png', '/home/mehdi/Bureau/PI/newdata/real/Real_006_17.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_016_18.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_003_14.PNG', '/home/mehdi/Bureau/PI/newdata/real/007007_002.png', '/home/mehdi/Bureau/PI/newdata/real/Real_002_13.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_001_06.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_001_09.PNG', '/home/mehdi/Bureau/PI/newdata/real/010010_001.png', '/home/mehdi/Bureau/PI/newdata/real/Real_012_03.PNG', '/home/mehdi/Bureau/PI/newdata/real/007007_001.png', '/home/mehdi/Bureau/PI/newdata/real/Real_003_12.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_004_08.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_015_20.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_001_11.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_009_10.PNG', '/home/mehdi/Bureau/PI/newdata/real/009009_004.png', '/home/mehdi/Bureau/PI/newdata/real/Real_009_12.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_016_23.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_006_22.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_001_14.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_006_06.PNG', '/home/mehdi/Bureau/PI/newdata/real/002002_002.png', '/home/mehdi/Bureau/PI/newdata/real/Real_002_06.PNG', '/home/mehdi/Bureau/PI/newdata/real/006006_002.png', '/home/mehdi/Bureau/PI/newdata/real/Real_015_19.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_001_01.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_004_12.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_014_01.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_003_23.PNG', '/home/mehdi/Bureau/PI/newdata/real/009009_000.png', '/home/mehdi/Bureau/PI/newdata/real/Real_006_20.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_015_02.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_002_20.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_009_03.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_015_03.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_012_02.PNG', '/home/mehdi/Bureau/PI/newdata/real/002002_003.png', '/home/mehdi/Bureau/PI/newdata/real/Real_002_23.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_004_18.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_015_10.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_002_18.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_003_10.PNG', '/home/mehdi/Bureau/PI/newdata/real/003003_002.png', '/home/mehdi/Bureau/PI/newdata/real/Real_014_10.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_002_16.PNG', '/home/mehdi/Bureau/PI/newdata/real/007007_003.png', '/home/mehdi/Bureau/PI/newdata/real/Real_006_14.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_015_16.PNG', '/home/mehdi/Bureau/PI/newdata/real/001001_002.png', '/home/mehdi/Bureau/PI/newdata/real/Real_006_11.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_015_12.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_014_19.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_016_04.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_006_07.PNG', '/home/mehdi/Bureau/PI/newdata/real/008008_000.png', '/home/mehdi/Bureau/PI/newdata/real/Real_015_17.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_004_17.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_016_02.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_016_05.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_001_22.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_004_23.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_004_09.PNG', '/home/mehdi/Bureau/PI/newdata/real/012012_000.png', '/home/mehdi/Bureau/PI/newdata/real/010010_004.png', '/home/mehdi/Bureau/PI/newdata/real/003003_003.png', '/home/mehdi/Bureau/PI/newdata/real/Real_015_22.PNG', '/home/mehdi/Bureau/PI/newdata/real/005005_002.png', '/home/mehdi/Bureau/PI/newdata/real/Real_006_01.PNG', '/home/mehdi/Bureau/PI/newdata/real/006006_003.png', '/home/mehdi/Bureau/PI/newdata/real/Real_012_14.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_003_17.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_004_24.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_014_16.PNG', '/home/mehdi/Bureau/PI/newdata/real/009009_001.png', '/home/mehdi/Bureau/PI/newdata/real/Real_014_22.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_002_15.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_001_17.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_009_06.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_009_07.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_012_11.PNG', '/home/mehdi/Bureau/PI/newdata/real/003003_000.png', '/home/mehdi/Bureau/PI/newdata/real/Real_003_22.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_014_23.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_001_05.PNG', '/home/mehdi/Bureau/PI/newdata/real/002002_001.png', '/home/mehdi/Bureau/PI/newdata/real/Real_012_08.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_002_08.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_001_15.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_004_10.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_002_10.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_014_02.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_012_20.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_012_07.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_015_11.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_002_01.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_006_05.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_002_22.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_014_24.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_004_16.PNG', '/home/mehdi/Bureau/PI/newdata/real/003003_004.png', '/home/mehdi/Bureau/PI/newdata/real/011011_003.png', '/home/mehdi/Bureau/PI/newdata/real/Real_014_08.PNG', '/home/mehdi/Bureau/PI/newdata/real/005005_000.png', '/home/mehdi/Bureau/PI/newdata/real/Real_004_02.PNG', '/home/mehdi/Bureau/PI/newdata/real/007007_000.png', '/home/mehdi/Bureau/PI/newdata/real/Real_003_02.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_003_03.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_016_21.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_009_20.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_012_05.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_002_11.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_001_04.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_016_20.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_004_03.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_014_17.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_009_24.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_015_06.PNG', '/home/mehdi/Bureau/PI/newdata/real/010010_000.png', '/home/mehdi/Bureau/PI/newdata/real/Real_016_24.PNG', '/home/mehdi/Bureau/PI/newdata/real/001001_004.png', '/home/mehdi/Bureau/PI/newdata/real/Real_012_24.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_004_13.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_003_11.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_002_04.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_003_09.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_003_15.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_003_21.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_009_11.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_014_21.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_002_19.PNG', '/home/mehdi/Bureau/PI/newdata/real/001001_001.png', '/home/mehdi/Bureau/PI/newdata/real/004004_000.png', '/home/mehdi/Bureau/PI/newdata/real/Real_001_20.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_016_15.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_016_10.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_014_05.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_012_13.PNG', '/home/mehdi/Bureau/PI/newdata/real/004004_002.png', '/home/mehdi/Bureau/PI/newdata/real/008008_001.png', '/home/mehdi/Bureau/PI/newdata/real/012012_003.png', '/home/mehdi/Bureau/PI/newdata/real/Real_016_16.PNG', '/home/mehdi/Bureau/PI/newdata/real/005005_003.png', '/home/mehdi/Bureau/PI/newdata/real/Real_016_13.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_002_05.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_014_12.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_012_06.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_006_15.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_004_22.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_002_07.PNG', '/home/mehdi/Bureau/PI/newdata/real/008008_003.png', '/home/mehdi/Bureau/PI/newdata/real/Real_009_21.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_009_09.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_004_21.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_003_05.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_004_14.PNG', '/home/mehdi/Bureau/PI/newdata/real/004004_004.png', '/home/mehdi/Bureau/PI/newdata/real/Real_016_17.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_016_03.PNG', '/home/mehdi/Bureau/PI/newdata/real/012012_004.png', '/home/mehdi/Bureau/PI/newdata/real/Real_015_21.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_015_05.PNG', '/home/mehdi/Bureau/PI/newdata/real/012012_002.png', '/home/mehdi/Bureau/PI/newdata/real/Real_016_14.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_003_07.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_009_02.PNG', '/home/mehdi/Bureau/PI/newdata/real/002002_004.png', '/home/mehdi/Bureau/PI/newdata/real/Real_012_18.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_014_13.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_015_07.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_006_13.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_016_11.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_012_17.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_004_04.PNG', '/home/mehdi/Bureau/PI/newdata/real/011011_000.png', '/home/mehdi/Bureau/PI/newdata/real/Real_014_07.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_003_19.PNG', '/home/mehdi/Bureau/PI/newdata/real/006006_004.png', '/home/mehdi/Bureau/PI/newdata/real/Real_003_20.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_001_02.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_012_16.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_002_12.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_006_04.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_003_04.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_015_14.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_009_17.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_009_22.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_003_24.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_014_11.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_016_06.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_015_18.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_001_19.PNG', '/home/mehdi/Bureau/PI/newdata/real/011011_002.png', '/home/mehdi/Bureau/PI/newdata/real/Real_014_04.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_002_14.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_009_14.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_003_08.PNG', '/home/mehdi/Bureau/PI/newdata/real/006006_000.png', '/home/mehdi/Bureau/PI/newdata/real/Real_001_13.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_006_03.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_004_20.PNG', '/home/mehdi/Bureau/PI/newdata/real/012012_001.png', '/home/mehdi/Bureau/PI/newdata/real/Real_012_10.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_002_03.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_016_08.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_015_15.PNG', '/home/mehdi/Bureau/PI/newdata/real/004004_003.png', '/home/mehdi/Bureau/PI/newdata/real/Real_009_15.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_012_12.PNG', '/home/mehdi/Bureau/PI/newdata/real/006006_001.png', '/home/mehdi/Bureau/PI/newdata/real/Real_016_12.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_012_15.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_014_14.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_009_23.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_014_18.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_009_05.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_004_06.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_001_03.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_015_01.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_006_08.PNG', '/home/mehdi/Bureau/PI/newdata/real/002002_000.png', '/home/mehdi/Bureau/PI/newdata/real/008008_002.png', '/home/mehdi/Bureau/PI/newdata/real/010010_002.png', '/home/mehdi/Bureau/PI/newdata/real/Real_006_10.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_002_17.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_004_15.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_009_16.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_015_24.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_004_07.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_016_22.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_003_13.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_001_16.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_015_23.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_004_01.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_002_09.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_014_03.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_001_12.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_002_24.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_006_24.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_016_09.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_001_08.PNG', '/home/mehdi/Bureau/PI/newdata/real/005005_004.png', '/home/mehdi/Bureau/PI/newdata/real/Real_014_06.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_012_09.PNG', '/home/mehdi/Bureau/PI/newdata/real/010010_003.png', '/home/mehdi/Bureau/PI/newdata/real/005005_001.png', '/home/mehdi/Bureau/PI/newdata/real/Real_006_23.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_014_20.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_012_01.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_006_18.PNG', '/home/mehdi/Bureau/PI/newdata/real/008008_004.png', '/home/mehdi/Bureau/PI/newdata/real/Real_009_04.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_001_24.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_015_13.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_003_18.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_009_08.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_003_16.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_012_19.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_003_06.PNG', '/home/mehdi/Bureau/PI/newdata/real/007007_004.png', '/home/mehdi/Bureau/PI/newdata/real/Real_001_23.PNG', '/home/mehdi/Bureau/PI/newdata/real/004004_001.png', '/home/mehdi/Bureau/PI/newdata/real/Real_002_21.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_014_15.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_015_08.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_001_07.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_015_04.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_002_02.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_009_19.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_001_10.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_012_21.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_006_02.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_004_19.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_012_23.PNG', '/home/mehdi/Bureau/PI/newdata/real/001001_000.png', '/home/mehdi/Bureau/PI/newdata/real/011011_001.png', '/home/mehdi/Bureau/PI/newdata/real/Real_012_22.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_016_07.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_009_01.PNG', '/home/mehdi/Bureau/PI/newdata/real/009009_003.png', '/home/mehdi/Bureau/PI/newdata/real/011011_004.png', '/home/mehdi/Bureau/PI/newdata/real/Real_006_19.PNG', '/home/mehdi/Bureau/PI/newdata/real/Real_009_13.PNG']\n",
      "/home/mehdi/Bureau/PI/newdata/real\n"
     ]
    }
   ],
   "source": [
    "#Creating Geniune Signature Data Path\n",
    "dataset_path = GeniuneDirectory\n",
    "checks_geniune = os.path.join(dataset_path,'*')\n",
    "checks_geniune = glob.glob(checks_geniune)\n",
    "print(checks_geniune)\n",
    "print(GeniuneDirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9278890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mehdi/Bureau/PI/newdata/forged\n"
     ]
    }
   ],
   "source": [
    "ForgedDirectory = os.path.join(CurrentWorkingDir,\"forged\")\n",
    "print(ForgedDirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e165b195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mehdi/Bureau/PI/newdata/forged\n"
     ]
    }
   ],
   "source": [
    "print(ForgedDirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb49ff19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mehdi/Bureau/PI/newdata/forged/Forged_003_01.png\n"
     ]
    }
   ],
   "source": [
    "#Creating Forged Signature Data Path\n",
    "dataset_path = ForgedDirectory\n",
    "checks_forged = os.path.join(dataset_path,'*')\n",
    "checks_forged = glob.glob(checks_forged)\n",
    "print(checks_forged[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68fa47e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299\n",
      "183\n"
     ]
    }
   ],
   "source": [
    "print(len(checks_geniune))\n",
    "print(len(checks_forged))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686766ca",
   "metadata": {},
   "source": [
    "## Applying Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b92f7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgbgrey(img):\n",
    "    # Converts rgb to grayscale\n",
    "    greyimg = np.zeros((img.shape[0], img.shape[1]))\n",
    "    for row in range(len(img)):\n",
    "        for col in range(len(img[row])):\n",
    "            greyimg[row][col] = np.average(img[row][col])\n",
    "    return greyimg\n",
    "\n",
    "def greybin(img):\n",
    "    # Converts grayscale to binary\n",
    "    blur_radius = 0.8\n",
    "    img = ndimage.gaussian_filter(img, blur_radius)  # to remove small components or noise\n",
    "#     img = ndimage.binary_erosion(img).astype(img.dtype)\n",
    "    thres = threshold_otsu(img)\n",
    "    binimg = img > thres\n",
    "    binimg = np.logical_not(binimg)\n",
    "    return binimg\n",
    "\n",
    "\n",
    "def preproc(path, img=None, display=True):\n",
    "    if img is None:\n",
    "        img = mpimg.imread(path)\n",
    "    if display:\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    grey = rgbgrey(img) #rgb to grey\n",
    "    if display:\n",
    "        plt.imshow(grey, cmap = matplotlib.cm.Greys_r)\n",
    "        plt.show()\n",
    "    binimg = greybin(grey) #grey to binary\n",
    "    if display:\n",
    "        plt.imshow(binimg, cmap = matplotlib.cm.Greys_r)\n",
    "        plt.show()\n",
    "    r, c = np.where(binimg==1)\n",
    "    # Now we will make a bounding box with the boundary as the position of pixels on extreme.\n",
    "    # Thus we will get a cropped image with only the signature part.\n",
    "    signimg = binimg[r.min(): r.max(), c.min(): c.max()]\n",
    "    if display:\n",
    "        plt.imshow(signimg, cmap = matplotlib.cm.Greys_r)\n",
    "        plt.show()\n",
    "    return signimg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77125d0d",
   "metadata": {},
   "source": [
    "## Creating Model CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a9496047",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image_Width = 512\n",
    "Image_Height = 512\n",
    "Image_Size = (Image_Width, Image_Height)\n",
    "Image_Channel = 3\n",
    "batch_size=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1f7633f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "## Conv layer 1\n",
    "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(Image_Width,Image_Height, Image_Channel)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## Conv layer 2\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## Conv layer 3\n",
    "model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## Conv layer 4\n",
    "model.add(Conv2D(256, (3,3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## Conv layer 5\n",
    "model.add(Conv2D(256, (3,3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## Conv layer 6\n",
    "model.add(Conv2D(512, (3,3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "578597d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 510, 510, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 510, 510, 32)     128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 255, 255, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 255, 255, 32)      0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 253, 253, 64)      18496     \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 253, 253, 64)     256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 126, 126, 64)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 126, 126, 64)      0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 124, 124, 128)     73856     \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 124, 124, 128)    512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 62, 62, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 62, 62, 128)       0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 60, 60, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 60, 60, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 30, 30, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 30, 30, 256)       0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 28, 28, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 28, 28, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 14, 14, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 14, 14, 256)       0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 12, 12, 512)       1180160   \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 12, 12, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 6, 6, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 18432)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               4718848   \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,884,034\n",
      "Trainable params: 6,881,026\n",
      "Non-trainable params: 3,008\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0b8c6096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "early_stop = EarlyStopping(patience=10)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=2, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "callbacks = [early_stop, learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ee2648",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0c206f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                  rescale=1./255,\n",
    "                                  shear_range=0.1,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  width_shift_range=0.1,\n",
    "                                  height_shift_range=0.1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "61f1d7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 482 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory('/home/mehdi/Bureau/PI/newdata',\n",
    "                                              target_size=Image_Size,\n",
    "                                              batch_size=32,\n",
    "                                              class_mode = 'categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "de10fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "904b90f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 263 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory('/home/mehdi/Bureau/PI/SignaturesDataTest',\n",
    "                                                  target_size=Image_Size,\n",
    "                                                  batch_size = 32,\n",
    "                                                  class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8df3c51a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehdi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0932 - accuracy: 0.6224WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "16/16 [==============================] - 160s 10s/step - loss: 1.0932 - accuracy: 0.6224 - val_loss: 0.7747 - val_accuracy: 0.3194 - lr: 0.0010\n",
      "Epoch 2/10\n",
      " 9/16 [===============>..............] - ETA: 1:05 - loss: 0.8898 - accuracy: 0.6319WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "16/16 [==============================] - -3433s -229573374us/step - loss: 0.8310 - accuracy: 0.6618 - val_loss: 4.9417 - val_accuracy: 0.3194 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6280 - accuracy: 0.7386WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "16/16 [==============================] - 169s 10s/step - loss: 0.6280 - accuracy: 0.7386 - val_loss: 2.5854 - val_accuracy: 0.3194 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7017 - accuracy: 0.7407WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "16/16 [==============================] - 165s 10s/step - loss: 0.7017 - accuracy: 0.7407 - val_loss: 8.9562 - val_accuracy: 0.3194 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6121 - accuracy: 0.7614WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "16/16 [==============================] - 169s 11s/step - loss: 0.6121 - accuracy: 0.7614 - val_loss: 12.2176 - val_accuracy: 0.3194 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5107 - accuracy: 0.7842WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "16/16 [==============================] - 177s 11s/step - loss: 0.5107 - accuracy: 0.7842 - val_loss: 8.8466 - val_accuracy: 0.3194 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5953 - accuracy: 0.7635WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "16/16 [==============================] - 172s 11s/step - loss: 0.5953 - accuracy: 0.7635 - val_loss: 4.9505 - val_accuracy: 0.3194 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5078 - accuracy: 0.8008WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "16/16 [==============================] - 164s 10s/step - loss: 0.5078 - accuracy: 0.8008 - val_loss: 6.0960 - val_accuracy: 0.3194 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4378 - accuracy: 0.8340WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "16/16 [==============================] - 168s 10s/step - loss: 0.4378 - accuracy: 0.8340 - val_loss: 12.2007 - val_accuracy: 0.3194 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3813 - accuracy: 0.8527WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "16/16 [==============================] - 160s 10s/step - loss: 0.3813 - accuracy: 0.8527 - val_loss: 13.7478 - val_accuracy: 0.3194 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "history = model.fit_generator(train_generator,\n",
    "                             epochs=epochs,\n",
    "                             validation_data=test_generator,\n",
    "                             validation_steps=len(test_generator),\n",
    "                             steps_per_epoch=len(train_generator),\n",
    "                             callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "142fbed6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlAAAAGrCAYAAAAPX6kCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABbpUlEQVR4nO3dd3hUVf7H8feZSaf33kSkNwFFUVCxgAVQ0cWuu2vZYllXf9bd1VXsu/aytrWsDQXsXUAsoAalhKIIgnRCCRBInTm/P+4EkpBAykzOlM/refLMzJ07935mEsg355x7jrHWIiIiIiJV53MdQERERCTWqIASERERqSYVUCIiIiLVpAJKREREpJpUQImIiIhUkwooERERkWpSASUSJ4wxHxhjLgj3vonIGPOcMeZ21zlEJHqpgBJxyBiTW+oraIzJK/X4nOocy1o72lr7fLj3rQ5jzFHGmNXhPm40Cr1Xa4z5P9dZRKTuqYAScchaW7/kC/gVOKXUtpdK9jPGJLlLKZW4ANgSuq0zxqP/u0Uc0z9CkShU0pJjjLnOGLMe+K8xpokx5l1jTLYxZmvofvtSr5lhjPl96P6FxpgvjTH3hfb9xRgzuob7djHGzDTG7DDGfGqMedQY878avKeeofPmGGMWGmPGlHruRGPMotA51hhjrgltbx56nznGmC3GmC8qKx6MMQ8aY1YZY7YbY+YYY44s9dwtxphJxpgXQudYaIwZXOr5gcaY70PPvQak7ee9ZADjgT8B3UofK/T8xcaYxaHjLTLGHBza3sEYMyX0PdxsjHmkVL7/lXp951DrVlLo8QxjzERjzFfALuAAY8xFpc6x3BhzabkMY40xc0OfxzJjzChjzBnGmDnl9vurMebNfb1fEdmbCiiR6NUaaAp0Ai7B+/f639DjjkAe8Mg+Xn8o8CPQHLgHeMYYY2qw78vAt0Az4BbgvOq+EWNMMvAO8DHQErgceMkY0z20yzPApdbaBkAfYFpo+1+B1UALoBVwI1DZ+lPfAQPwPrOXgdeNMaULoTHAq0Bj4G1Cn50xJgV4E3gx9NrXgdP385ZOB3JD+34EnF/qvZ6B9zmdDzQMnXezMcYPvAusBDoD7UJ5quo8vJ+DBqFjbARODp3jIuD+UoXaIcALwLWh9zscWBF6312MMT1LHffc0HsXkWpQASUSvYLAP6y1BdbaPGvtZmvtZGvtLmvtDmAiMGIfr19prX3KWhsAngfa4BUhVd7XGNMRGAL83VpbaK39Eu+XcHUNBeoDd4WOMw2vmDgr9HwR0MsY09Bau9Va+32p7W2ATtbaImvtF7aSBTyttf8LfUbF1tp/AalA91K7fGmtfT/0Hl8E+pfKlgw8EDrHG3jF2L5cALwWOtbLwFmhIhHg98A91trvrOdna+1K4BCgLXCttXantTY/9HlW1XPW2oWh91dkrX3PWrssdI7P8YrTkla33wHPWms/sdYGrbVrrLVLrLUFwGt4RRPGmN54xdy71cghIqiAEolm2dba/JIHxpgMY8x/jDErjTHbgZlA41DLRkXWl9yx1u4K3a1fzX3bAltKbQNYVc33Qeg4q6y1wVLbVuK1woDXonMisNIY87kx5rDQ9nuBn4GPQ91U11d2glBX1GJjzDZjTA7QCK9FrcT6Uvd3AWmhLrK2wJpyhdnKfZynA3A0UDJG7S28Lr+TQo87AMsqeGkHvEK1uLJj70eZz90YM9oYMzvUtZmD9/mVvN/KMoBXIJ8damE8D5gUKqxEpBpUQIlEr/ItLX/Fa1E51FrbEK9bBqCybrlwWAc0DY35KdGhBsdZC3QoN36pI7AGINRaMxave+9NYFJo+w5r7V+ttQcApwBXG2NGlj94aLzTdcCZQBNrbWNgG1X7bNYB7cp1b3bcx/7n4f3f+Y7xxqctxyugSrrxVgFdK3jdKqCjqfiCgJ1A6c+4dQX77P55MMakApOB+4BWoff7Pnveb2UZsNbOBgrxWqvORt13IjWiAkokdjTAG/eUY4xpCvwj0icMdT1lArcYY1JCLUOn7O91xpi00l94Y6h2Av9njEk2xhwVOs6roeOeY4xpZK0tArYDgdBxTjbGHBgqbkq2Byo4ZQOgGMgGkowxf8cbG1QVs0KvvcIYk2SMOQ2vu60y5wO34o23Kvk6HTjJGNMMeBq4xhgzyHgONMZ0Cn0G64C7jDH1Qp/NsNAx5wLDjTEdjTGNgBv2kzkFr4syGyg23qD/40s9/wxwkTFmpDHGZ4xpZ4zpUer5F/DGgBVXsxtRREJUQInEjgeAdGATMBv4sI7Oew5wGLAZuB1vDM2+unza4RV6pb864A2mHo2X/zHgfGvtktBrzgNWhLomLyM0RgfoBnyKN2B7FvCYtXZGBef8CPgA+Amv+y2fKnY1WmsLgdOAC4GtwG+AKRXta4wZijdm6FFr7fpSX2/jdTWeZa19HW982svADrwWtaah8VKnAAfiTVmxOnQurLWf4H2u84E57GdMUmgM3BV4LXVb8VqS3i71/LeEBpbjtcR9jnfxQYkX8Qbrq/VJpIZMJeMxRUQqFLrMf4m1NuItYBIZxph0vKv4DrbWLnWdRyQWqQVKRPbJGDPEGNM11BU0ChiL16oisesPwHcqnkRqTrMbi8j+tMbr0mqG1+30B2vtD24jSU0ZY1bgDTYf5zaJSGxTF56IiIhINakLT0RERKSa6rQLr3nz5rZz5851eUoRERGRGpkzZ84ma22Lip6r0wKqc+fOZGZm1uUpRURERGrEGFPpqgTqwhMRERGpJhVQIiIiItWkAkpERESkmpzPA1VUVMTq1avJz8/f/85SobS0NNq3b09ycrLrKCIiIgnBeQG1evVqGjRoQOfOnSm7GLpUhbWWzZs3s3r1arp06eI6joiISEJw3oWXn59Ps2bNVDzVkDGGZs2aqQVPRESkDu23gDLGPGuM2WiMyarguWuMMdYY07w2IVQ81Y4+PxERkbpVlRao54BR5TcaYzoAxwG/hjmTiIiISFTbbwFlrZ0JbKngqfuB/wNiejG9nJwcHnvssRq99sQTTyQnJ6fK+99yyy3cd999NTqXiIiIRI8ajYEyxowB1lhr51Vh30uMMZnGmMzs7OyanC6i9lVABQKBfb72/fffp3HjxhFIJSIiItGs2gWUMSYDuAn4e1X2t9Y+aa0dbK0d3KJFhcvJOHX99dezbNkyBgwYwLXXXsuMGTM4+uijOfvss+nbty8A48aNY9CgQfTu3Zsnn3xy92s7d+7Mpk2bWLFiBT179uTiiy+md+/eHH/88eTl5e3zvHPnzmXo0KH069ePU089la1btwLw0EMP0atXL/r168eECRMA+PzzzxkwYAADBgxg4MCB7NixI0KfhoiIiFRFTaYx6Ap0AeaFBi+3B743xhxirV1fmzC3vrOQRWu31+YQe+nVtiH/OKV3pc/fddddZGVlMXfuXABmzJjBt99+S1ZW1u5pAZ599lmaNm1KXl4eQ4YM4fTTT6dZs2ZljrN06VJeeeUVnnrqKc4880wmT57MueeeW+l5zz//fB5++GFGjBjB3//+d2699VYeeOAB7rrrLn755RdSU1N3dw/ed999PProowwbNozc3FzS0tJq96GIiIhIrVS7Bcpau8Ba29Ja29la2xlYDRxc2+IpmhxyyCFl5lR66KGH6N+/P0OHDmXVqlUsXbp0r9d06dKFAQMGADBo0CBWrFhR6fG3bdtGTk4OI0aMAOCCCy5g5syZAPTr149zzjmH//3vfyQlefXtsGHDuPrqq3nooYfIycnZvV1ERETc2O9vYmPMK8BRQHNjzGrgH9baZyIRZl8tRXWpXr16u+/PmDGDTz/9lFmzZpGRkcFRRx1V4ZxLqampu+/7/f79duFV5r333mPmzJm8/fbb3HbbbSxcuJDrr7+ek046iffff5+hQ4fy6aef0qNHjxodX0RERGpvvwWUtfas/TzfOWxpHGjQoME+xxRt27aNJk2akJGRwZIlS5g9e3atz9moUSOaNGnCF198wZFHHsmLL77IiBEjCAaDrFq1iqOPPpojjjiCl19+mdzcXDZv3kzfvn3p27cvs2bNYsmSJSqgREQkcf06G9ofAj5384EnfF9Qs2bNGDZsGH369GH06NGcdNJJZZ4fNWoUTzzxBP369aN79+4MHTo0LOd9/vnnueyyy9i1axcHHHAA//3vfwkEApx77rls27YNay1/+ctfaNy4MX/729+YPn06fr+fXr16MXr06LBkEBERiSlFefDx3+C7p+CUh2DQBc6iGGvrbhqnwYMH28zMzDLbFi9eTM+ePessQ7zS5ygiInFt3XyY/HvY9CMc9mc45m+QHNmLqowxc6y1gyt6LuFboERERCSKBYMw62H47Dao1xzOexO6Hu06lQooERERiVLbVsPUy2DFF9DzFK/bLqOp61SACigRERGJRllT4N2rIFAMYx6BgeeCN/9kVFABJSIiItEjfzu8fy3MfxXaDYbTnoRmXV2n2osKKBEREYkOv86GKZfAtlUw4joYfi34k12nqpAKKBEREXErUASf3wNf3AeNOsBFH0LHQ12n2icVUDVQv359cnNzq7xdREREKrF5GUy5GNbMgf5nw+i7Ia2h61T7pQJKRERE6p618MOL8MH1XjfdGc9B71Ndp6oyd3OgR4nrrruOxx57bPfjW265hX/961/k5uYycuRIDj74YPr27ctbb71V5WNaa7n22mvp06cPffv25bXXXgNg3bp1DB8+nAEDBtCnTx+++OILAoEAF1544e5977///rC/RxERkaiyawu8di68fTm0HwR/+DqmiieIthaoD66H9QvCe8zWfWH0XZU+PWHCBK666ir++Mc/AjBp0iQ+/PBD0tLSmDp1Kg0bNmTTpk0MHTqUMWPGYKpwCeWUKVOYO3cu8+bNY9OmTQwZMoThw4fz8ssvc8IJJ3DTTTcRCATYtWsXc+fOZc2aNWRlZQGQk5MTlrctIiISlZZNg6l/gF2b4bjbvFnFHa5pV1PRVUA5MHDgQDZu3MjatWvJzs6mSZMmdOzYkaKiIm688UZmzpyJz+djzZo1bNiwgdatW+/3mF9++SVnnXUWfr+fVq1aMWLECL777juGDBnCb3/7W4qKihg3bhwDBgzggAMOYPny5Vx++eWcdNJJHH/88XXwrkVEROpYUT58divMfgyad4dzXoc2/VynqrHoKqD20VIUSePHj+eNN95g/fr1TJgwAYCXXnqJ7Oxs5syZQ3JyMp07dyY/P79Kx6tsfcHhw4czc+ZM3nvvPc477zyuvfZazj//fObNm8dHH33Eo48+yqRJk3j22WfD9t5ERESc27AQJl8MGxfCIZfAcf+E5HTXqWolugooRyZMmMDFF1/Mpk2b+PzzzwHYtm0bLVu2JDk5menTp7Ny5coqH2/48OH85z//4YILLmDLli3MnDmTe++9l5UrV9KuXTsuvvhidu7cyffff8+JJ55ISkoKp59+Ol27duXCCy+M0LsUERGpY8EgfPMEfHoLpDWCc96Abse5ThUWKqCA3r17s2PHDtq1a0ebNm0AOOecczjllFMYPHgwAwYMoEePHlU+3qmnnsqsWbPo378/xhjuueceWrduzfPPP8+9995LcnIy9evX54UXXmDNmjVcdNFFBINBAO68886IvEcREZE6tX0dvPkHWD4dDhoNYx6G+i1cpwobU1l3UyQMHjzYZmZmltm2ePFievbsWWcZ4pU+RxERiRqL34G3r4CiPBh1Bwy6KKrWsasqY8wca+3gip5TC5SIiIiER0EufHi9N79TmwFw+tPQvJvrVBGhAkpERERqb3WmN6P4ll/giKvhqBsgKcV1qohRASUiIiI1FyiGL/8NM+6Chm3hwveg8zDXqSJOBZSIiIjUzNYVMOUSWPUN9D0DTrwP0hu7TlUnVECJiIhI9VgL816F96/1Boef9jT0O8N1qjqlAkpERESqLm8rvPsXWDgVOh4Op/0HGnd0narOqYASERGRqvllJky9DHI3wMi/w7CrwOd3ncqJ2Fu9L8xycnJ47LHHqv26E088UQv/iohIYigugI//Bs+P8ZZg+d0ncORfE7Z4AhVQlRZQgUBgn697//33ady4cYRSiYiIRInsH+HpkfD1QzDoQrh0JrQ72HUq56KqC+/ub+9myZYlYT1mj6Y9uO6Q6yp9/vrrr2fZsmUMGDBg9xIrbdq0Ye7cuSxatIhx48axatUq8vPzufLKK7nkkksA6Ny5M5mZmeTm5jJ69GiOOOIIvv76a9q1a8dbb71FenrFiyQ+9dRTPPnkkxQWFnLggQfy4osvkpGRwYYNG7jssstYvnw5AI8//jiHH344L7zwAvfddx/GGPr168eLL74Y1s9HRESkQtbCd0/DxzdDSj2Y8Ar0ONF1qqiR8C1Qd911F127dmXu3Lnce++9fPvtt0ycOJFFixYB8OyzzzJnzhwyMzN56KGH2Lx5817HWLp0KX/6059YuHAhjRs3ZvLkyZWe77TTTuO7775j3rx59OzZk2eeeQaAK664ghEjRjBv3jy+//57evfuzcKFC5k4cSLTpk1j3rx5PPjgg5H5EERERErL3QgvnwnvXwOdj4A/zFLxVE5UtUDtq6WorhxyyCF06dJl9+OHHnqIqVOnArBq1SqWLl1Ks2bNyrymS5cuDBgwAIBBgwaxYsWKSo+flZXFzTffTE5ODrm5uZxwwgkATJs2jRdeeAEAv99Po0aNeOGFFxg/fjzNmzcHoGnTpuF6myIiIhX78UN4609QmAuj74VDLo7JdewiLaoKqGhQr1693fdnzJjBp59+yqxZs8jIyOCoo44iPz9/r9ekpqbuvu/3+8nLy6v0+BdeeCFvvvkm/fv357nnnmPGjBmV7mutxeiHVkRE6kLhLvj4Jsh8Flr1hdOfgpZapL4yCd+F16BBA3bs2FHhc9u2baNJkyZkZGSwZMkSZs+eXevz7dixgzZt2lBUVMRLL720e/vIkSN5/PHHAW8A+/bt2xk5ciSTJk3a3W24ZcuWWp9fRERkL2t/gP8M94qnwy+Hiz9T8bQfCd8C1axZM4YNG0afPn1IT0+nVatWu58bNWoUTzzxBP369aN79+4MHTq01ue77bbbOPTQQ+nUqRN9+/bdXbw9+OCDXHLJJTzzzDP4/X4ef/xxDjvsMG666SZGjBiB3+9n4MCBPPfcc7XOICIiAkAwAF89CNMnQr2WcP7bcMAI16ligrHW1tnJBg8ebDMzM8tsW7x4MT17qsqtLX2OIiJSLTmrvEkxV34JvcbByfdDhsbalmaMmWOtHVzRcwnfAiUiIpJwFrwB714NNgDjHof+Z2mgeDWpgIqQP/3pT3z11Vdltl155ZVcdNFFjhKJiEjCy98G710DCyZB+0O8deyaHuA6VUxSARUhjz76qOsIIiIie6z8GqZcCtvXwFE3wJHXgF9lQE3pkxMREYlngSKYcSd8eT807gi//Qg6DHGdKuapgBIREYlXm36GKb/3pikYcC6MvgtSG7hOFRdUQImIiMQba2HOc/DRjeBPgTNfgF5jXaeKKwk/kaaIhFGg2Bugumy66yQiiWvXFnj1HHj3Kmg/BP44S8VTBKiAqqb69eu7jiASvb66H757Cib/HnbuvfC2iNSBz26FpR/D8RPhvDehYVvXieKSCigRCY8NC2HG3dDpCO9S6Q+vd51IJPEU5UPWVOhzOhz+Z/Dp13ykRNUYqPV33EHB4iVhPWZqzx60vvHGSp+/7rrr6NSpE3/84x8BuOWWWzDGMHPmTLZu3UpRURG33347Y8fuv/kzNzeXsWPHVvi6F154gfvuuw9jDP369ePFF19kw4YNXHbZZSxfvhyAxx9/nMMPPzwM71qkjgWKvBmN0xt7Yy2+fRI+vwv6joeDTnCdTiRxLP0YCrZBvzNdJ4l7+y2gjDHPAicDG621fULb7gVOAQqBZcBF1tqcCOaMmAkTJnDVVVftLqAmTZrEhx9+yF/+8hcaNmzIpk2bGDp0KGPGjMHsZ5bWtLQ0pk6dutfrFi1axMSJE/nqq69o3rz57kWBr7jiCkaMGMHUqVMJBALk5uZG/P2KRMQX/4b18+E3/4N6zeDIq2HRW/DuX+CPsyGtoeuEIolh/mvemnZdtJ5dpFWlBeo54BHghVLbPgFusNYWG2PuBm4ArqttmH21FEXKwIED2bhxI2vXriU7O5smTZrQpk0b/vKXvzBz5kx8Ph9r1qxhw4YNtG7dep/HstZy44037vW6adOmMX78eJo3bw5A06beWkPTpk3jhRe8j9Xv99OoUaPIvlmRSFg3H2beA33GQ89TvG1JqTD2EXj6WPj0Fjj5304jiiSEvK1eC9SQ32uCzDqw30/YWjvTGNO53LaPSz2cDYwPc646NX78eN544w3Wr1/PhAkTeOmll8jOzmbOnDkkJyfTuXNn8vPz93ucyl5nrd1v65VITCouhDf/COlN4cR7yz7XfjAM/SPMftQbj9F5mJuMIoli0VsQKFT3XR0Jx+iy3wIfVPakMeYSY0ymMSYzOzs7DKcLvwkTJvDqq6/yxhtvMH78eLZt20bLli1JTk5m+vTprFy5skrHqex1I0eOZNKkSWze7F2VVNKFN3LkSB5//HEAAoEA27dvj8C7E4mgL+6DDQvglAcqXsX9mJugcSd4+3IoyqvzeCIJZf4kaH4QtBngOklCqFUBZYy5CSgGXqpsH2vtk9bawdbawS1atKjN6SKmd+/e7Nixg3bt2tGmTRvOOeccMjMzGTx4MC+99BI9evSo0nEqe13v3r256aabGDFiBP379+fqq68G4MEHH2T69On07duXQYMGsXDhwoi9R5GwWzsXZt4H/SZAj5Mq3ielHox5CLYsgxl31Wk8kYSS8yus/Ar6ngnq8agTxlq7/528Lrx3SwaRh7ZdAFwGjLTW7qrKyQYPHmwzMzPLbFu8eDE9e/asTmapgD5HqVPFBfDk0bBrM/xpNqQ32ff+b18OP7wEF38GbQfWTUaRRPLFv735n66YC027uE4TN4wxc6y1gyt6rkYtUMaYUXiDxsdUtXgSkTjy+T2wcSGc8uD+iyeA426Dei3grT97Ux6ISPhY611912Goiqc6tN8CyhjzCjAL6G6MWW2M+R3eVXkNgE+MMXONMU9EOGdUWbBgAQMGDCjzdeihh7qOJVI31szxVnUfcA50H1W116Q39q7E25AFXz0QyXQiiWf9AsheosHjdawqV+GdVcHmZ8IZItauUuvbty9z5851HWO3qnTDioRFUb531V39VnDCHdV7bY+ToPepXutVzzHQontkMookmvmvgS/J+/cldcb5HO9paWls3rxZRUANWWvZvHkzaWlprqNIIvj8Lu8v3TEPea1K1TX6Hm9g+Vt/hmAg7PFEEk4wAFmTodvxFV8JKxHjfKat9u3bs3r1aqJ1ioNYkJaWRvv27V3HkHi3OhO+ehAGngfdjqvZMeq3hFF3wdRL4bun4dBLw5tRJNGs+AJ2rIN+d7pOknCcF1DJycl06aJBbyJRrSgP3vwDNGgLJ0ys3bH6/QYWvA6f3goHjYImncKTUSQRzZ8EqQ29f0tSp5x34YlIDJg+ETb9BGMfhrRaLjlkDJz8gHf7zpXeFUQiUn1FebDobW9MYXK66zQJRwWUiOzbr9/A14/AoAuh6zHhOWbjDnDsLbB8Osx9OTzHFEk0P34AhTt09Z0jKqBEpHKFu7yuu0Yd4Pjbw3vswb+DjofBRzfAjg3hPbZIIpg/yetW73yE6yQJSQWUiFRu2u3eMixjH4bUBuE9ts8HYx72pkZ4/5rwHlsk3u3cDD9/An3Hg8/vOk1CUgElIhVb+TXMfsxrKTrgqMico3k3OOp6WPy2t5K8iFTNwikQLFb3nUMqoERkb4U74a0/eWOVjvtnZM91+OXQuh+8dw3kbY3suUTixYLXoWUvaNVn//tKRKiAEpG9ffZP2LIcxj4GqfUjey5/Mox9xFuY+KObInsukXiw5RdY9Y3X+hRDq3jEGxVQIlLWii/hmyfgkEuhy5F1c842/eGIq2DuS/DzZ3VzTpFYteB177bvGW5zJDgVUCKyR0Gut9Zdky5w7D/q9tzD/w+adYN3rvJyiMjerPXWvut0BDTSChQuqYASkT0+vQVyfoVxj3lr1tWl5DSvK2/bKph2W92eWyRWrP0BNv+sweNRQAWUiHiWfw7fPQVD/wCdDneToeNQOORi+OY/3gSeIlLW/EngT4FeY10nSXgqoEQECnbAW3+Gpl3hmL+5zTLy717XxNt/9uaIEhFPoBiy3vDWvUtv7DpNwlMBJSLwyd+9rrNxj0FKhtssqQ3glAe8tfe+uM9tFpFosnwG7MxW912UUAElkuiWTYPMZ+GwP3ldaNHgwGOh/9nw5f2wfoHrNCLRYcEkbzHvbse7TiKogBJJbPnb4a3LvavfjrnZdZqyTpgI6U28CT0Dxa7TiLhVkAuL34Hep0JSqus0ggookcT28U2wYy2MexyS012nKSujKZx4H6ybB7MecZ1GxK0f34eiXdDvN66TSIgKKJFE9fOn8P0L3lIqHYa4TlOxXmOhx8kw407Y9LPrNCLuzH8NGnWADlHSzS4qoEQSUl6O13XXvDscdaPrNJUzBk76F/hT4Z0rIBh0nUik7uVuhGXTvZnHffq1HS30nRBJRB/dBLkb4NTHvQkso1mD1t54qJVfwZz/uk4jUveypoANqPsuyqiAEkk0P30Ec//nrT3XbpDrNFUz8Fw44Cj45B+wbbXrNCJ1a/5r0LoftOzhOomUogJKJJHkbYV3roSWvWDEda7TVJ0xcMqD3l/h7/7FWw9MJBFs+hnWfq+5n6KQCiiRRPLhDd54inGPxd6l0E06e7OUL/14z2r0IvFuwSTAQJ/xrpNIOSqgRBLFkvdh3itw5F+h7UDXaWrmkEug/RD44DrIzXadRiSyrPW67w4YAQ3buE4j5aiAEkkEu7bAu1dBqz4w/FrXaWrO54cxj0BhLnwYQ12QIjWx+jvYukKDx6OUCiiRRPDBdbBrszdhZlKK6zS107KHVwRmTfZa1UTi1fzXICnNmwtNoo4KKJF4t/gdbxzF8GuhTT/XacJj2FXQsje8dzXkb3OdRiT8AkXe9AXdT4S0hq7TSAVUQInEs52bvavWWvf1xj7Fi6QUGPuIN5fVJ393nUYk/H7+DPK2qPsuiqmAEolnH1zrzTo+7gnwJ7tOE17tDobD/gxznoNfZrpOIxJe81+D9KZw4EjXSaQSKqBE4tXCN71xQiOug9Z9XKeJjKNugKYHwNuXQ+Eu12lEwiN/u7d4cJ/T4u8PnziiAkokHuVme+OD2gzwZhyPVykZcMpD3pVK0ye6TiMSHkveheJ8dd9FORVQIvHo/b9CwQ7vqrt4/wu2y5Ew6CKY/RisnuM6jUjtzX/Nmzi2/RDXSWQfVECJxJusKbDoLTjqemjVy3WaunHcrVC/Nbz9ZygudJ1GpOa2r4Pln3utT8a4TiP7oAJKJJ7kboT3/gptD4bDr3Sdpu6kNYKT74eNi+DL+12nEam5rDcAC3219l20UwElEi+s9aYsKNwZ6rpLcp2obnUfBX3PgJn3wsbFrtOI1Mz8Sd4fQM0PdJ1E9kMFlEi8WPCGN/j0mJu82boT0ai7vEkH3/ozBAOu04hUz8bFsH6+Bo/HCBVQIvFgx3p4/xpv0Olhf3adxp16zWH0PbAmE755wnUakeqZPwmM35u+QKKeCiiRWGctvHOVd9nzuMe9BXcTWZ/T4aBR8NltsOUX12lEqiYYhAWvQ9ejoX5L12mkClRAicS6+a/BTx/AMX+D5t1cp3HPGDjp3+BLgneu8ApMkWi3ajZsW6XuuxiiAkoklm1fBx/8H3QYCkP/4DpN9GjUDo7/p7fEyw8vuk4jsn/zX4PketDjJNdJpIr2W0AZY541xmw0xmSV2tbUGPOJMWZp6LZJZGOKyF6shXeu9OY9GveYuu7KO/hC6HQEfHSzV2iKRKviAlg41SueUuq5TiNVVJUWqOeAUeW2XQ98Zq3tBnwWeiwidWnuy7D0Izj2H9Csq+s00cfngzEPQaDAmxtLXXkSrZZ+DPnb1H0XY/ZbQFlrZwJbym0eCzwfuv88MC68sURkn7atgQ+vh46HwyGXuk4TvZp1haNvgh/f8/7CF4lG8ydBvRZwwFGuk0g11HQMVCtr7TqA0G2llwwYYy4xxmQaYzKzs7NreDoR2c1ab3B0sBjGPeq1tEjlhv4R2g6E96+FXeX/FhRxLC8HfvoQ+oxPvMlvY1zE/+e11j5prR1srR3cokWLSJ9OJP798CL8/Ckceys0PcB1mujnT4Ixj0B+Dnx4g+s0ImUtegsChdDvDNdJpJpqWkBtMMa0AQjdbgxfJBGpVM4q+PBG6HwkDPm96zSxo3UfOOJqmP8qLP3EdRqRPeZPgmYHesu3SEypaQH1NnBB6P4FwFvhiSMilbIW3r4cbBDGPqKuu+oafg206OFNOlqww3UaEe8PopVfeoPHjXGdRqqpKtMYvALMArobY1YbY34H3AUcZ4xZChwXeiwikTTnOVg+HY6/DZp0dp0m9iSlel1529fAp7e6TiMCWW94t33VfReL9jtizVp7ViVPjQxzFhGpzNaV8PHN0GUEDP6t6zSxq8MQb8LR2Y956411Otx1IklU1sK816D9IdC0i+s0UgPqAxCJdsEgvB1aIHjsI2rqr61jbobGHeGtP0NRnus0kqg2ZEH2Yuh3puskUkMqoESiXeYz3pIkJ0z0fvFL7aTUg1Megi3L4PO7XaeRRDX/NW+9xt6nuU4iNaQCSiSabfkFPvkHdD0GDr5g//tL1XQ9GgaeC189BGvnuk4jiSYYgAWT4cDjoF4z12mkhlRAiUSrYNDrZvL5YczD6roLt+Nvh3rNve7RQJHrNJJIVnwJO9Zq7qcYpwJKJFp995R3ifMJd0Cj9q7TxJ/0JnDSv2D9Avj6IddpJJHMnwQpDeCg0a6TSC2ogBKJRpuXeV13Bx7ndTVJZPQ8BXqNgxl3Q/ZPrtNIIijK82Yf7zUGUjJcp5FaUAElEm2CQXjrT+BPgTEPqesu0k68F5LTvUlKg0HXaSTe/fQhFO7Q1XdxQAWUSLT55gn4dRaMvgsatnWdJv7Vbwmj7oJVs+G7p12nkXg3fxLUb+0txyQxTQWUSDTZ9DN8discNAr6VzaHrYRd/wnQdSR8egvk/Oo6jcSrnZth6cfQd7x3cYjENBVQItEiGIC3/ghJaXDyA+q6q0vGwCkPePffucqbJVok3BZNhWCxt/adxDwVUCLRYvZjsOobGH0PNGzjOk3iadwRjr0Fln0G8151nUbi0fzXoUVPaN3XdRIJAxVQItEg+yf47DbofpIGl7o05PfQYSh8eD3kbnSdRuLJll+8cXb9zlDrcpxQASXiWjAAb/7Bu6T55Pv1n6tLPp+33mBRHrx/res0Ek8WvOHd9tXkmfFCBZSIa18/DGsy4cT7oEEr12mkeTc46jpY9CYsfsd1GokH1npr33UapvUs44gKKBGXNi6B6RO9CR37nO46jZQ4/ApvnMp7f4W8ra7TSKxbNxc2L1X3fJxRASXiSqAY3rwMUhvASeq6iyr+ZBjzCOzcBB/f7DqNxLr5k7yJcXuNdZ1EwkgFlIgrXz0Aa3/w1mOr38J1Gimv7QAYdgX88D9YNt11GolVgWJv/FO34731FyVuqIAScWHDQphxF/Q+1fuS6DTiOmh2ILxzBRTudJ1GYtEvM2DnRs39FIdUQInUtUCRd9VdWiNv4LhEr+R0rysv51eYdrvrNBKL5r/u/VvvdrzrJBJmKqBE6tqX98O6eXDyv6Fec9dpZH86HQZDLobZj8Oq71ynkVhSuNO7krPXWEhOc51GwkwFlEhd2rgEPr8b+ozXgNJYcuw/oGE7eOtPUFzgOo3EiiXvQ9FOdd/FKRVQInXp++fB+GD03a6TSHWkNvDWytv0I8xUt6tU0fzXoGF76Hi46yQSASqgROpKMABZU7yxEOq6iz3djoN+E+DLf8P6LNdpJNrlZsOyad7SLT79qo1H+q6K1JVfZ0HueuhzmuskUlOj7vQuRX/7cggGXaeRaLZwCtgA9NXkmfFKBZRIXcmaDMkZcNAo10mkpjKawvETYe33sGCS6zQSzea/Bq36QqterpNIhKiAEqkLgWJY9BZ0Hw0p9Vynkdroewa0HQif/RMKd7lOI9Fo8zJYM0dLt8Q5FVAideGXz2HXZuit7ruY5/PBCXfA9jUw61HXaSQazZ8EGOg73nUSiSAVUCJ1IWsKpDaEA491nUTCodPh0HOMN6fXjvWu00g0sdbrvutyJDRs6zqNRJAKKJFIKy7wJtPrcbIm04snx90KgULNUC5lrc6Erb9o7qcEoAJKJNJ+/gwKtkGf010nkXBqegAceqm32PD6Ba7TSLSY/xokpUHPU1wnkQhTASUSaVmTIb0pHDDCdRIJt+HXQHpj+Ogmr+tGElugyJu+oPtob/07iWsqoEQiqXAn/Pi+t2yLP9l1Ggm39CZw1A3eRQJLP3adRlxbNs27WERzPyUEFVAikfTTR1C0S9138Wzwb6HZgfDxzV4LhCSu+a95RbUuFkkIKqBEIilrMtRv7V21JfHJnwzH3QabfoI5z7lOI64U7PAWD+59GiSluE4jdUAFlEik5G+DpZ9A71PB53edRiKp+2jofCTMuBPyclynERcWvwvFebr6LoGogBKJlCXvQ6BA3XeJwBg4YSLs2gJf/Mt1GnFh/mvQuBN0OMR1EqkjKqBEIiVrMjTqCO0Hu04idaFNfxhwNnzzBGz5xXUaqUvb13kXEvQ70yumJSGogBKJhF1bYPl06HOa/kNNJMfcDL4k+PQW10mkLmVNBhvU1XcJRgWUSCQsfhuCxV4BJYmjYVsYdiUsehN+/cZ1GqkrCyZ5C0y3OMh1EqlDKqBEIiFrsndpe+t+rpNIXTv8cmjQBj66AYJB12kk0jYugXXz1PqUgFRAiYTbjvXwyxfe4HF13yWelHpwzN9gzRxvVmqJbwsmgfHpYpEEpAJKJNwWvQVYbz4YSUz9z/JaHz+9BYryXKeRSAkGYf7rcMDR0KCV6zRSx1RAiYRb1mRo1Qda9nCdRFzx+bxpDbatgtmPuU4jkbLqG9j2q+Z+SlC1KqCMMX8xxiw0xmQZY14xxqSFK5hITMr51ftPVYPHpctw6H4SfHE/5G50nUYiYf5rkJwBPU5ynUQcqHEBZYxpB1wBDLbW9gH8wIRwBROJSQunerfqvhOA4/7pzU49/Q7XSSTcigu8f+89ToLU+q7TiAO17cJLAtKNMUlABrC29pFEYljWZGg3CJp2cZ1EokHzA2HI7+H752HDItdpJJyWfgL5Oeq+S2A1LqCstWuA+4BfgXXANmvtx+X3M8ZcYozJNMZkZmdn1zypSLTb9LN3ObOuxpHSRlwHqQ3g45tdJ5FwWjAJMpp7A8glIdWmC68JMBboArQF6hljzi2/n7X2SWvtYGvt4BYtWtQ8qUi0WzgFMN7iwSIlMpp6RdSyz2Dpp67TSDjk5cCPH3p/LPmTXKcRR2rThXcs8Iu1NttaWwRMAQ4PTyyRGGMtLHgDOh3uzUYtUtqQi6FJF68VKlDsOo3U1uK3vYXC1X2X0GpTQP0KDDXGZBhjDDASWByeWCIxZuMi2PSjrr6TiiWleAPKsxfDDy+4TiO1NX8SNO0K7Q52nUQcqs0YqG+AN4DvgQWhYz0ZplwisSVrijcbcc+xrpNItOp5CnQ8HKZNhPztrtNITW1bDSu+9FqftNJAQqvVVXjW2n9Ya3tYa/tYa8+z1haEK5hIzLDWu/quywior3F+UgljvMk1d22CL+93nUZqasEbgIW+410nEcc0E7lIba39Abb+oqvvZP/aHQz9JsCsR71JVyX2zJ8E7YdAs66uk4hjKqBEaitrMviSoefJrpNILBj5N6816tNbXSeR6lqfBRsXavC4ACqgRGonGPRmIz7wWEhv4jqNxIJG7eHwyyHrDVj1nes0Uh0LJoEvSVOVCKACSqR2Vn0D29eo+06qZ9hVUL8VfHSjN4ZOol8wCPNfh64joV5z12kkCqiAEqmNrMmQlA7dR7tOIrEktT4cczOs/hYWvek6jVTFyi9hx1rod6brJBIlVECJ1FSg2Pvld9AJWkxUqm/AOdCqD3zyDyjKd51G9mf+a5BSH7qf6DqJRAkVUCI1teIL2Jmt7jupGZ8fjr8dclbCt/9xnUb2pSgfFr0NPcdASobrNBIlVECJ1FTWZEhpAN2Oc51EYlXXo6HbCTDzPti5yXUaqcxPH0LBduh3huskEkVUQInURHGhtx5Wj5MgOd11Gollx98GhTthxl2uk0hl5k/yBv13GeE6iUQRFVAiNbFsGuRvU/ed1F6L7jD4Ish8FrJ/dJ1Gytu1BZZ+DH3P8LpdRUJUQInUxMIp3rxPBxzlOonEg6NugJR68PHfXCeR8ha9CcEiXX0ne1EBJVJdRXmw5D1vcdikFNdpJB7Uaw7Dr4GlH8Gy6a7TSGnzJ0Hz7tC6n+skEmVUQIlU19KPoTBX3XcSXodcCo07wcc3QzDgOo0AbF0Bv87yWp+McZ1GoowKKJHqypoM9VpC5yNdJ5F4kpwGx94CG7Jg7kuu0wjAgte92766+k72pgJKpDoKdsBPH0HvcRpQKuHX+1RofwhMu937WRN3rPW67zoeDk06uU4jUUgFlEh1/PgBFOer+04iwxg44Q7I3QBfPeg6TWJbNw82/aS5n6RSKqBEqiNrMjRs77USiERChyHQZzx8/TBsW+06TeKaPwl8ydBrnOskEqVUQIlU1a4t8PNn0OdU8OmfjkTQsf/wupA+u811ksQUDEDWG946lxlNXaeRKKXfAiJVteRdbz4Ydd9JpDXuCIf9Eea/Cmu+d50m8fzyudeNqrmfZB9UQIlUVdZkaHoAtBngOokkgiOuhozm8NFNXmuU1J35kyC1kbdOoUglVECJVEXuRvhlptf6pPlgpC6kNYRjboJfv4bF77hOkzgKd3qfd68x3tQSIpVQASVSFYveAhtU953UrYHnQ4ue8MnfvQWsJfJ+/MCbKLffb1wnkSinAkqkKrKmQMte0LKn6ySSSPxJcPztsPUX+O4p12kSw/xJ0LAddBrmOolEORVQIvuzbY3XjdL7NNdJJBF1Oxa6joTP7/auBJXI2bkJfv4U+o7XlbayX/oJEdmfhVO92z4qoMSR40Mzk39+t+sk8S1rCtiAuu+kSlRAiexP1mTvyrtmXV0nkUTVqhccfAF89zRs+tl1mvg1/zVo1Qda9XadRGKACiiRfdmyHNZ+r8Hj4t7RN0JSmjegXMJv8zJYk6m5n6TKVECJ7EvWFO+296luc4jUbwlHXg0/vudNqSHhteB1wHjL6IhUgQookX3JmgIdhkLjDq6TiMDQP0KjDvDRjd5yIxIe1nrdd52PgEbtXKeRGKECSqQyGxfDxoXqvpPokZwOx94C6xfAvFddp4kfa+Z43fUaPC7VoAJKpDJZU8D4oNdY10lE9uhzOrQbBNNu82bNltqbPwn8qd7s4yJVpAJKpCLWelffdT4SGrRynUZkD2PghDtgxzr4+mHXaWJfoMj7t959FKQ1cp1GYogKKJGKrJsHW5ap+06iU8eh0GscfPUgbF/rOk1sWzYddm1S951UmwookYpkTQZfEvQ8xXUSkYodewsEi2Ha7a6TxLb5r0F6EzjwONdJJMaogBIpz1pv9vGuIyGjqes0IhVr2gUOvRTmvuy1mEr1FeyAJe9505QkpbhOIzFGBZRIeau/g22rtHSLRL8jr/FaTz66ySv8pXqWvAfFedBXk2dK9amAEikva7J3RU73E10nEdm39MbeDOUrvoAfP3CdJvbMfw0ad4QOh7pOIjFIBZRIacGA13130PGQ1tB1GpH9G3QhND8IPvmbd0WZVM2ODbB8htf65NOvQqk+/dSIlLbyK8jdoKvvJHb4k+G422Dzz5D5rOs0sSNrMtig1r6TGlMBJVJa1mRIrgfdTnCdRKTqDjoBuoyAGXdC3lbXaWLD/NegTX9o0d11EolRKqBESgSKYNFb0ONESMlwnUak6oyBEyZCXg7MvM91muiX/SOsm6u5n6RWVECJlFg+w/vrXd13Eota94WB58I3/4HNy1yniW7zJ3nLNOnfutRCrQooY0xjY8wbxpglxpjFxpjDwhVMpM5lTfaWcuh6jOskIjVzzM3gT4FP/+E6SXQqyoOvH4Fvn/S6PBu0dp1IYlhtW6AeBD601vYA+gOLax9JxIGifFj8rjfzeFKq6zQiNdOgNRxxFSx+B1Z+7TpN9AgUQeZ/4aGD4eOboP1gOOlfrlNJjKtxAWWMaQgMB54BsNYWWmtzwpRLpG79/AkU7lCTvsS+w/4MDdrCRzdCMOg6jVvBIMx/HR4ZAu9eBY07wAXvwnlToVlX1+kkxtWmBeoAIBv4rzHmB2PM08aYeuV3MsZcYozJNMZkZmdn1+J0IhGUNRkymkPn4a6TiNROSgYc+w9Y+wMseN11GjeshSXvwxNHwJTfQ0p9OHsS/PYj6HKk63QSJ2pTQCUBBwOPW2sHAjuB68vvZK190lo72Fo7uEWLFrU4nUiEFOTCjx9C73HgT3KdRqT2+p4JbQbAZ7dC4S7XaerW8s/h6WPh1bOgOB/GPwuXzvSmejDGdTqJI7UpoFYDq62134Qev4FXUInElp8+9NbD6q217yRO+Hxwwh2wfQ3MftR1mrqxOhOeHwMvjIEd6+CUh+BP33rd8pppXCKgxn9uW2vXG2NWGWO6W2t/BEYCi8IXTaSOZE2BBm2goy4ilTjSeRj0OBm+uB8Gng8NWrlOFBkbFsK0ifDje143/Al3wuDfQnKa62QS52rbX3E58JIxJgVYDlxU+0gidSgvxxtAPuRi/ZUq8ee4f8JPh8L022HMw67ThNeW5TD9Tm+cV2oDOPpmGHqZd1+kDtSqgLLWzgUGhyeKiANL3oNAoa6+k/jUrCsccgnMfgwOuRRa93GdqPa2r4XP74EfXgRfMgy70vvKaOo6mSQYjZiVxJY1GRp3gnYavidxavg1MPclb/6j896M3YHUOzfDl/+G756GYAAGXeS9N02GKY6ogJLEtXOTt3zLsCtj95eKyP5kNIWjrocPr4eln8BBx7tOVD3522HWo95X0U7oNwGOug6adHadTBKcCihJXIveAhtQ953Ev8G/g2+f8lqhuh4N/mTXifavKM/L/OX9kLcFeo6Bo2+Clj1cJxMBtJiwJLKsKdC8O7Tq7TqJSGQlpcDxt8Gmn2DOc67T7FugCL57Bh4aCJ/8DdoOhIunw29eVPEkUUUtUJKYtq+FlV/BUTeo+04SQ/cTodMRMONO6Hemt3B2NAkGYMEbMOMO2LoCOgyF05+Gzke4TiZSIbVASWJa+CZgoY8mz5QEYQycMBF2bYEvomghXWu9hbwfHwZTL/GmITj7dfjthyqeJKqpBUoSU9ZkaN0PmndznUSk7rQdAP3PgtmPe5NNuh6IvWw6TLsN1syBZgfC+P9Cr3Gak01ign5KJfFsXQFrMjV4XBLTyL+B8cOnt7jLsOo7eP4UeHEc7NgAYx6BP37jtQireJIYoRYoSTwLp3q3vU91m0PEhYZtYdgV8PndcOgfoOOhdXfu9VkwfSL8+L637Mqou2HQhVp2RWKSSn1JPFmTof0QaNLJdRIRNw6/Auq3ho9u9MYgRdrmZTD59/DEEbDiKzjmZrhynrf0iooniVEqoCSxZP8E6xeo+04SW2p9rytvTab3B0WkbFsD71wJjwzxBoofcRVcOReGX+tlEIlh6sKTxLJwCmC8gaoiiaz/WfDNE95YqB4nQXJ6+I69c5M3Aea3T4ENwpDfwZHXQINW4TuHiGMqoCRxWOv9td35CGjYxnUaEbd8fjh+Irwwxrsq78ira3/M/G2lll3Z5RVpI65Td7nEJRVQkjg2ZHkzMQ/9g+skItHhgBFw0Gj44t8w8Dyo36JmxyncBd+VLLuyFXqN9ZZdadE9vHlFoojGQEniyJrsXb7dc6zrJCLR4/jboDjPmwG8uooL4bunQ8uu/B3aDYJLZsCZL6h4krinFihJDCXdd12PhnrNXKcRiR7Nu3mLDX/3FBxyCbTsuf/XBAOw4HWYfgfkrISOh8H4Z6HzsMjnFYkSaoGSxLBmDuT8qqvvRCoy4jpIaQAf37zv/ayFxe/A44fD1Eu99fTOeQMu+kDFkyQcFVCSGLImgz/Fu9pIRMqq1wxGXAs/f+p9lWctLJsGTx0Dr53rtUCd8Rxc8jl0O04LcktCUgEl8S8YgKwp0O346FuBXiRaHHKJtzbeRzdDoHjP9lXfhpZdORV2ZsPYR+GPs72Z/LXsiiQwjYGS+PfrLMhd762zJSIVS0qF4/4Jk86HH170Zuufdhv89CHUawGj7/GWXUlKdZ1UJCqogIo1GxZC065a/qA6siZDcgYcNMp1EpHo1nOMNyD8wxu8K/PSGsHIv8Ohl0FKPdfpRKKK2l9jyepMb/Dmy2dAUb7rNLEhUAyL3vKKJ/0CENk3Y2DUXd6M4Udc7a1Xd+Rf9W9HpAJqgYoln90KKfXhl5kw+XdwxvPg17dwn375HHZt1tV3IlXVdoBXOInIPqkFKlYsn+EVTsfcDKPuhiXvwjtXQDDoOll0y5oCqQ3hwGNdJxERkTii5otYYC189k9o2B4GXeSNf8rPgRl3QlpjOGGiLiOuSHGBN2dNj5M1ZkxERMJKBVQsWPKeNxHkmEf2FAIjroNdW2D2o5DRBIZf6zZjNPr5MyjYpu47EREJOxVQ0S4YgGm3Q7MDvZXNS5QM9szP8Z5PbwJDfu8sZlTKmgzpTb0FU0VERMJIBVS0W/A6ZC+G8f/de8C4z+dNape/Hd67xuvO6zveScyoU7gTfnwf+v0G/Mmu04iISJzRIPJoVlzoLdbZuh/0GlfxPv5kOOO/0GmYtzbVTx/XacSo9dNHULRL3XciIhIRKqCi2ffPeyudj/z7vpdMSE6Hs16BVr1h0nmwclbdZYxWWZOhfmvodLjrJCIiEodUQEWrwl0w817oeHjVLsFPawjnToFGHeDl38C6+ZHPGK3yt8HST0JrdfldpxERkTikAipaffsfyN3gtT5VdYqCes3hvKmQ2gD+dxpsXhbZjNFqyfsQKFD3nYiIRIwKqGiUlwNfPgDdjodOh1XvtY07wPlvgg3CC+Ng25rw54t2WZOhUUdoP9h1EhERiVMqoKLRrEe86QmOublmr2/eDc6dDHlb4cVTYefmsMaLaru2wPLp0OdUTS4qIiIRowIq2uRuhFmPeeN32vSv+XHaDoSzX4WtK+Cl8VCwI2wRo9rityFYrO47ERGJKBVQ0eaLf0NxPhxdw9an0jofAWc+D+vmwatnQ1F+7Y8Z7bIme5OOtu7nOomIiMQxFVDRJOdXyHwGBpwNzQ8MzzG7j4Zxj3sLEU/+HQSKw3PcaLRjPfzyhdf6pO47ERGJIBVQ0eTzu73bo64P73H7/wZG3Q1L3oV3roBgMLzHjxaL3gIs9D7NdRIREYlzWsolWmxaCnNfhkMvg0btw3/8oZd5A9Nn3Okt+XLCxPhrpcmaDK36QMserpOIiEicUwEVLabdDknpcMTVkTvHiOu8q9RmPwoZTWD4tZE7V13L+RVWfePNmyUiIhJhKqCiwdq5sOhNGP5/UL9F5M5jDIy6y2uJmnY7pDeBIb+P3Pnq0sKp3q2670REpA6ogIoG027zipnD/xz5c/l8MPZRyN8O713jdef1HR/580Za1mRoNwiadnGdREREEoAGkbu24iv4+VM44i+Q1qhuzulPhjP+6y20O/VS+OnjujlvpGz62ZuqQXM/iYhIHal1AWWM8RtjfjDGvBuOQAnFWq/1qX5rGHJx3Z47OR3OegVa9YZJ58PKWXV7/nBaOAUw3uSjIiIidSAcLVBXAovDcJzEs/QT+HUWjPg/SMmo+/OnNYJzp3hX/b38G1g3v+4z1Ja1sOANrzWtYVvXaUREJEHUqoAyxrQHTgKeDk+cBBIMwrR/QpPOMPA8dznqNYfzpkJqA/jfabB5mbssNbFxEWz6Ua1PIiJSp2rbAvUA8H9ApTMzGmMuMcZkGmMys7Oza3m6OLJoKqxfAEfdCEkpbrM07gDnvwk2CC+Mg21r3OapjqwpYHzQa5zrJCIikkBqXEAZY04GNlpr5+xrP2vtk9bawdbawS1aRPAS/VgSKIZpE6Flr+i5Aq55Nzh3MuRthRdPhZ2bXSfaP2u9q++6jIjs9A8iIiLl1KYFahgwxhizAngVOMYY87+wpIp3c1+CLcvgmJvB53edZo+2A+HsV2HrCnhpPBTscJ1o39b+AFt/0dV3IiJS52pcQFlrb7DWtrfWdgYmANOsteeGLVm8Ksr31rxrNxi6n+g6zd46HwFnPu9NC/Dq2V7eaJU1GXzJ0PNk10lERCTBaB6oupb5LGxf4y05Eq1r0XUfDeMeg19mwuTfeV2O0SYY9GYfP/BYbxJSERGROhSWAspaO8Naq2aA/SnYAV/c543ZOWCE6zT71n8CjLoblrwL71zhFSzRZNU3XiGq7jsREXFAS7nUpdmPw67NMPIfrpNUzdDLvHXzZtzptfIcf3v0tJplTfYWX+4+2nUSERFJQCqg6squLfD1w9DjZGg/yHWaqhtxnZd91iNeETX8GteJvC7FRW/CQSdAan3XaUREJAGpgKorX97vdeEdc7PrJNVjDIy6y2uJmnYbpDeGIb93m2nFF7AzW913IiLijAqourB9HXz7JPT7DbTs6TpN9fl8MPZRyN8O710DaY3dzl+VNRlSGkC349xlEBGRhKar8OrCzHsgGICjb3CdpOb8yXDGf70156ZeCj997CZHcSEsfht6nOQtiCwiIuKACqhI27Icvn8BBl3grXsXy5LT4axXoFVvmHQ+rJxV9xmWTYP8bdDntLo/t4iISIgKqEibfqc32ePwa10nCY+0RnDuFGjUHl7+DaybX7fnXzjF60I84Oi6Pa+IiEgpKqAiacNCWPA6HHopNGjtOk341GsO502F1Abwv9Ng87K6OW9RHix5D3qNcb8As4iIJDQVUJE0bSKkNoRhV7pOEn6NO8D5b4INwgvjYPvayJ9z6cdQmKur70RExDkVUJGy6jv48T0YdjlkNHWdJjKad4NzJ0PeVq+I2rk5sufLmgz1WkLnIyN7HhERkf1QARUp0/4JGc3h0D+4ThJZbQfC2a/C1hXw0nhvrqtIKNgBP30EvceBzx+Zc4iIiFSRCqhIWDbdW4h3+DWJMVN25yPgzOdh3Tx49Wwoyg//OX78AIrz1X0nIiJRQQVUuFkLn/0TGraHwb91nabudB8N4x7zCsfJv/OWWwmnrMneZ9r+kPAeV0REpAZUQIXbkndh7fdw1PWQlOo6Td3qPwFG3e19Bu9cAcFgeI67awv8/Bn0OdWbFV1ERMQxLeUSTsEATLsdmnWD/me5TuPG0Mu8dfNm3OktPnz87d56erWx5F0IFqn7TkREooYKqHBa8DpkL4EzngN/An+0I67zWo1mPeIVUcOvqd3xsiZD0wOgzYCwxBMREamtBP4tH2bFhTD9DmjTH3qOdZ3GLWNg1F1eS9S02yC9MQz5fc2OlbvRG1d15F9r35IlIiISJiqgwuX75yFnJZz0b43TAe8zGPso5G+H967xll/pO776x1n0ljdZp7rvREQkiug3fTgU7oSZ90LHw+HAka7TRA9/MpzxX+h0OEy9FH76uPrHyJoCLXpCy57hzyciIlJDKqDC4dsnIXcDjPy7upnKS06Hs16BVr1h0vmwclbVX7ttDfz6tVqfREQk6qiAqq28HPjyAeh2PHQ6zHWa6JTWCM6dAo3aw8u/gfULqva6hVO92z6nRS6biIhIDaiAqq2vH/YGSx/zN9dJolu95nDeVEhtAC+eBpuX7f81WZO9K++adY14PBERkepQAVUbuRth9uPQ+zRo0891mujXuAOc/ybYgLf48Pa1le+7Zbk3Iam670REJAqpgKqNL/7lrc929E2uk8SO5t3g3MmQt9UronZurni/rCnebe9T6yyaiIhIVamAqqmcXyHzWRh4DjQ/0HWa2NJ2IJz9KmxdAS+Nh4Ide++TNQU6DPVarURERKKMCqia+vxuwHizbkv1dT4Cznwe1s2DV8+Govw9z21cDBsXqvtORESilgqomsj+Cea+7M2u3ai96zSxq/toGPeYN9P45N9BoNjbnjUFjA96JfiM7iIiErVUQNXE9ImQnAFHXu06SezrPwFG3e0tGPzOlRAMelffdT4SGrRynU5ERKRCWsqlutbOhUVvel139Zq7ThMfhl7mTQUx405vcPmWZTDsStepREREKqUCqrqm3QbpTeCwP7lOEl9GXAe7tsC3/wFfEvQ8xXUiERGRSqmAqo4VX8HPn8Jx//Rm15bwMQZG3eWtn+dLgoymrhOJiIhUSgVUVVkLn/0TGrSBQy5xnSY++XxwwkTXKURERPZLg8irauknsGo2DL/WWyBXREREEpYKqKoIBr3Wpyad4eDzXacRERERx9SFVxWLpsKGBXDaU94YHREREUloaoHan0ARTJsILXtpZmwREREB1AK1f3Nf9uYlmvAK+Pyu04iIiEgUUAvUvhTle2vetR/iLTsiIiIiglqg9i3zGdi+Bk59wpunSERERAS1QFWuYAd88S844CjoMtx1GhEREYkiKqAqM+sx2LUZRv7ddRIRERGJMiqgKrJrC3z9MPQ4GdoNcp1GREREokyNCyhjTAdjzHRjzGJjzEJjzJXhDObUl/dDYS4cc7PrJCIiIhKFajOIvBj4q7X2e2NMA2COMeYTa+2iMGVzY/ta+PZJ6D8BWvZ0nUZERESiUI1boKy166y134fu7wAWA+3CFcyZmfdCMABHXe86iYiIiESpsIyBMsZ0BgYC31Tw3CXGmExjTGZ2dnY4Thc5W5bD9y/AoAu9de9EREREKlDrAsoYUx+YDFxlrd1e/nlr7ZPW2sHW2sEtWrSo7ekia/qd4EuG4de4TiIiIiJRrFYFlDEmGa94eslaOyU8kRzZsBAWvA6HXgoNWrtOIyIiIlGsNlfhGeAZYLG19t/hi+TItNshtSEMi5+LCUVERCQyatMCNQw4DzjGGDM39HVimHLVrVXfwY/vw7DLIaOp6zQiIiIS5Wo8jYG19ksg9heIsxY+uxXqtYBD/+A6jYiIiMQAzUS+fAas+AKOvAZS67tOIyIiIjEgsQsoa+Gzf0KjDjD4ItdpREREJEYkdgG15F1Y+703aWZSqus0IiIiEiMSt4AKBrwr75ofBP0muE4jIiIiMaQ2a+HFtvmTIHsJnPE8+BP3YxAREZHqS8wWqOJCmHEHtOkPPce4TiMiIiIxJjGbXr5/HnJ+hZPvB19i1pAiIiJSc4lXPRTuhM/vgU7DoOtI12lEREQkBiVeC9S3T8LOjfCbF8HE/jygIiIiUvcSqwUqLwe+fAC6nQAdh7pOIyIiIjEqsQqorx+G/Bw45mbXSURERCSGJU4BlbsRZj8OfU6HNv1cpxEREZEYljgF1Bf/guJ8OPom10lEREQkxiVGAZXzK2Q+CwPPhWZdXacRERGRGJcYBdSMuwEDI/7PdRIRERGJA/FfQGX/BPNehiG/h0btXacRERGROBBXBVT2jgKWbtjBrsLiPRun3w7JGXDk1e6CiYiISFyJq4k03563ltveXQRA44xkRtRfw4Pb32JG69/y8/fbade4iLaN02nXJJ1m9VIwmkhTREREaiCuCqjjeraief0U1uTksTYnj98suZvtpgH/t/ZINq5YXGbf1CQf7ULFVLvG6V5hVepx60ZpJPvjqoFOREREwiSuCqiOzTLo2CzDe7DiS5ibCcfdxjeHn8r2vGJW5+xizVavuFqz+yufxYs3sim3oMyxfAZaNUwrU1i1bZxO+1L366fG1ccnIiIiVRSfFYC18Nlt0KANHHIxxhgaZSTTKKMRvds2qvAl+UUB1m3LZ83WPNbk7GJNzp77c1fl8EHWOooCtsxrGqUn7269al+6JSt0v3l9dROKiIjEo/gsoJZ+DKtmw8n3Q3J6lV6SluynS/N6dGler8LnA0FL9o6CPS1XpVqyVm3Zxezlm8ktKC7zmpSSbsLG6bRtnEa7xhmh1qs02jfOoHWjNFKS1E0oIiISa+KvgAoGvdanJl1g4HlhO6zfZ2jdKI3WjdIY1KlJhftsyyuqoIvQK7am/5hN9o6y3YTGQMsGqaEuwoxQYbWni7Bd43QapCWH7T2IiIhIeMRfAbVwCmxYAKc9Df66LT4apSfTKD2ZXm0bVvh8QXGAdTn5ZQqrkgHv81fn8GFW3l7dhA3TkvbqImzVMI0WDVJp0SCV5vVTaZyejM+nrkIRkWgQtEECwQDFtphAMEDABigOFhOwgd3bw7FPwAbK3C//XNAGvS+CWGv3PA59WWyZ+4FgoOw2awnYireVPububaWOWfJcZa+vcJu1BNmzLUiQYDBYdlup93TP8Hs4ofMJzr7P8VVABYpg+kRo2dtbNDjKpCb56dy8Hp0r6SYMBi2bcgtYXa64WrM1j9Vb8/jmly3syC/e63VJPkPz+iUFVUqZ4qpFg1RalDzXIJUGqUkalyUJY/d/uKH/gEt+QQRsoMx/zBVt32uf0H/wJbd+48dnfBhj8Bv/Xrc+9vGc8e3+Mhj8Pm//3dvi5N9oyedV8ku9KFi0p0AIFlNsi71f+qUKgJJioSrP795W+v4+nt/rcbnipHxRUlHhErTBfb6+2O79f7Qr5X/mDKbMz2z5bT7j814T2lb+57vkZ7TSbb7Qz3apbbt/1ivaFtpe1W3lX9+lURenn298FVBzX4Yty+GsV8EXe2OLfD5Dy4ZptGyYxsEdK+4m3J5fRPaOgt1fm3L33M/O9b4WrdvOptxCAkG71+tTk3yVF1ih25ah++kp/ki/5TKstRQGCykOFu+1vcxj9n5f5beVf01l59vnMSo6TxWyVOU15f8SLPPFPp4rvU9w//uW/0tvr+fK/UVX6XPVPGbp2/Lby+9f0TFKv8eS8wWClWwPFToV7meD+/3+RKOKftHt/iXi81VYnO1VlFX2XMnrKincSp4rX3CULyZKFyglhUNF21xJ8iWR7EvGb/z4fX6STFLZW18SfrPntmQ/v/GT4k8hKSlp9+OSfXzGt2f/cs+VPC5/vnDus9fjfeTwmdj7HRhr4quAajsADvszHDTKdZKIaZiWTMO0ZLq2qL/P/YJBy9ZdhWzKLQwVV/mhgqtwd8H16+ZdfL9yK5t3FlZ4jPqpPpo38NG0vqFJfUOjDEvDDGiQbqmXZklPDZKWEiQlKUAxhRQUF5AfyKcgUFDmfn5x6DaQT0FxQZn7pfcvCBRUqSCRulP6L9EKv6j8ucp+gZd/nORLqtJ+FW0rUwiUKjD2dax9vabSY4Xep9/n7WOM2avroaRbo6SwraiQrKi7pKIisibFcpWK7wqOVdJVVL4bpvQv7CRfEqkm1fslXWpbyS/rMoWKL2mv50u2lS9cytzfx/Olz7m/50sei0RafBVQbfp7X3GkpBWg5K+/omBRjQqU/OJ8CpILKGhYgC8jn8bNC0gPFNAqUEBecT67ivLJK8onP5BPYaCAomAhQYrZDGwGCAA7Ql9V4CeZJF8qKb5UUv2ppCenkZGcRv3kdBqmNKSFvwWpSamk+dNI9aeSlrTnNsnsv5vRsPfz5V9Tfh9jjPdLImgpDlqKAyW3QYoCluJgkEAQigLB0HNBigJQHAhSHLTe9tDrSvYvOUZRyTEC5beVvGbvd2CtIcnnJ8XvJyUpiRS/n1R/EilJflKSvPtpSX5Sk5NI9SeRmpxEWpJ3m56URFrocXpyEukpyd79lCQyUpJJT/ZuU/3+vZrVq/RVqrlcRET2FlcFVFGgiPxAfplm5KJg0V794SX98KWbmWuyX8m+pfcr35xdUf98VfYrOW757qya8Bt/mSKlTMHiT6NBRoPd90sXNRUVOD5SKCjykZfvY2e+ITffx/Y82LbLsjXXsnUnbNoRJHtHAflFe3ef+Aw0q+91GzYPdR9mNEilccn4rYxU0pL9FBQFyS8OUFAUpKA4QH5RgILioHcbei5/93PB3c+V7FdQVP75PbcV9GxWWbLfhIoaP6lJPtKSfaQl+8lI8m5TU73btN3P+0lN9pGa5CctdJvsNxQUBdlVGCCvKEBeYTF5RQF2FXr5dxUGyMsPkFsYILsoQF6h97WrKFCqW9YCRaGvyvkMZKQkeRlT/KQn+0kP3Wak+ElL8ZNRsq3k+ZLnkv1kpCSRnuILFWl7HyM92a8LGEQkIcVVAfXKkle4N/PeOjlX6f71ipqVSzdhl36c5kvb534lzeFl+ud9oW2hJu6SIqjCFpxQEVT6frKv7qdCsNayszDAppKxWZWM2fp5ww6ycwv2uvpwf3yGvQuVJB+pyX7Sknw0zkgps93bd08hU3r/Pc9Xsm/SniLI77hYKCwOhoquQKjoKt5TdO0uyAKlirNAmeKspBDLLwywYUf+7uKsZJ+C4uqPGUpN8pUtrFK8wqte6DYjxU+91HK3KV5BVi+1ZN8kMlL9u28zkv0kaSmliAgErfezEPp5KH0/r9QfIalJZQvl8kV2WrJaKCWxxVUBNaj1IK4ZfM1exU1JcZJskvfqY9+rCPL5y+xXuqgpPYBP9s0YQ/3UJOqnJlV61WEJay3b8vYMji8oDu7ValO66ElL9ifsOoUpST5Sknw0So9MURwMWu+Xabniy7tfTF5hcHfRtvu5cq1kXgFXzOadhazamseugmJ2FgbYWVBMcTWa/1KSfLuLsN2FVqqf9ORSj1P8ZKTuuc1I9pfZt3xxFs2/9INBS35x2UImrzBYwbbA7u9Rfqn7JfuW3RYoVywFKQyEb2B9mdbI0sVVqZbNtFKtmuUfp5VvES33ODUper9fIqYqVyuFy+DBg21mZmadnU9EokthsVeA7SwMsKugmF2FAXYWFrOrIHQbKrRKb98VKshKXrOz5HGBd7urcK8BZpUyBjKSSxVdpQqtjPLFWqniLD3FX6YQ8/tMhS03eYUB8ouDlbbs7HnsdTOXLnRq0voHe4qYtCQfaeVajEqKldKP05J9+3w+PdlPSpLZ3S1eUjSXLeCCu7ueS4o3r8AueU9B8gsD7AoV3fmh1tKadJ9XVqSV3la+i7r045KirPzjtFIt1GrtlMoYY+ZYawdX9FxctUCJSHTzWtBSaJwRvmOWtNyUFFS7b0sVXHn7KMB2FgTIyStibU5emcKtti01qUm+cl1ee7o3m9YrW8iUfr50K056qYKn/PPpMdZCY62lMBAkvzBYrpWzOFSAlRoTWFKklRojWFKIlXRd5+QVsX5bfrnxgzUr0vw+43Xplx4OsLvrvmxruNf1X/q+f/drSw8J2L2t1HEqOnaKP3a+h1KWCigRiWk+nwm1ICUBqWE7bmGoJamkZax00VUctJUWPyXj5jS4vixjTKjo8NOIyHRBW+tdIVu65W+v21BR5l1sUvYCk8q25RUFyMkr3LMtdOFKyX61YQx7iqpSxVmZgq18EVeqsCt7sUrZ4yT7vQItJcm7n5q0536ZbX6ffl5rQAWUiEgFdo83y9B6lLHCGENKkonoOMHySlrWqlOQlVwpXOa2uNx+pYq0HfnFFR4vvzhAuEbh+H1mr2Ir2W92/zsoXYyV3q/k+T3bTGhqFu9+RUVbSpKPVL+P5KS9C7zSx/SOFb0tdCqgREREaqh0yxppdXtua70550oXYvmlCrKiQJDC4tBX6P7ubaVui4othYFA6Hm712uLAnv2zy0oLnOckv0LiwMUBbxisqJVMGqjpJAqX7T97eReHN29ZVjPVR0qoERERGKQMYZkvyHZ76N+avT8Og+EJhIuKFNoebcF5YqvksKtMGDLFniVFH17jmvrrJWxMtHziYfB+jvuoGDxEtcxREREpJyU0Fe4pP7SA268MYxHrB5duykiIiJSTXHVAtXaYSUqIiIiiUMtUCIiIiLVpAJKREREpJpUQImIiIhUU60KKGPMKGPMj8aYn40x14crlIiIiEg0q3EBZYzxA48Co4FewFnGmF7hCiYiIiISrWrTAnUI8LO1drm1thB4FRgbnlgiIiIi0as2BVQ7YFWpx6tD28owxlxijMk0xmRmZ2fX4nQiIiIi0aE2BVRFq/vttQCOtfZJa+1ga+3gFi1a1OJ0IiIiItGhNgXUaqBDqcftgbW1iyMiIiIS/WpTQH0HdDPGdDHGpAATgLfDE0tEREQketV4KRdrbbEx5s/AR4AfeNZauzBsyURERESiVK3WwrPWvg+8H6YsIiIiIjFBM5GLiIiIVJMKKBEREZFqUgElIiIiUk3G2r2mborcyYzJBlZG+DTNgU0RPodElr6HsU/fw9im71/s0/cwPDpZayucxLJOC6i6YIzJtNYOdp1Dak7fw9in72Fs0/cv9ul7GHnqwhMRERGpJhVQIiIiItUUjwXUk64DSK3pexj79D2Mbfr+xT59DyMs7sZAiYiIiERaPLZAiYiIiESUCigRERGRaoqrAsoYM8oY86Mx5mdjzPWu80j1GGM6GGOmG2MWG2MWGmOudJ1Jqs8Y4zfG/GCMedd1Fqk+Y0xjY8wbxpgloX+Lh7nOJNVjjPlL6P/QLGPMK8aYNNeZ4lHcFFDGGD/wKDAa6AWcZYzp5TaVVFMx8FdrbU9gKPAnfQ9j0pXAYtchpMYeBD601vYA+qPvZUwxxrQDrgAGW2v7AH5ggttU8SluCijgEOBna+1ya20h8Cow1nEmqQZr7Tpr7feh+zvw/uNu5zaVVIcxpj1wEvC06yxSfcaYhsBw4BkAa22htTbHaSipiSQg3RiTBGQAax3niUvxVEC1A1aVerwa/fKNWcaYzsBA4BvHUaR6HgD+Dwg6ziE1cwCQDfw31A37tDGmnutQUnXW2jXAfcCvwDpgm7X2Y7ep4lM8FVCmgm2aoyEGGWPqA5OBq6y1213nkaoxxpwMbLTWznGdRWosCTgYeNxaOxDYCWg8aQwxxjTB633pArQF6hljznWbKj7FUwG1GuhQ6nF71GwZc4wxyXjF00vW2imu80i1DAPGGGNW4HWhH2OM+Z/bSFJNq4HV1tqSlt838AoqiR3HAr9Ya7OttUXAFOBwx5niUjwVUN8B3YwxXYwxKXiD5t52nEmqwRhj8MZeLLbW/tt1Hqkea+0N1tr21trOeP/+pllr9ZdvDLHWrgdWGWO6hzaNBBY5jCTV9ysw1BiTEfo/dSS6ECAiklwHCBdrbbEx5s/AR3hXHTxrrV3oOJZUzzDgPGCBMWZuaNuN1tr33UUSSTiXAy+F/hBdDlzkOI9Ug7X2G2PMG8D3eFc2/4CWdYkILeUiIiIiUk3x1IUnIiIiUidUQImIiIhUkwooERERkWpSASUiIiJSTSqgRERERKpJBZSIiIhINamAEhEREamm/wdU+yDu/38PCQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6224066615104675, 0.6618257164955139, 0.7385892271995544, 0.7406638860702515, 0.7614107728004456, 0.7842323780059814, 0.7634854912757874, 0.8008298873901367, 0.8340249061584473, 0.8526970744132996]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.plot(history.history['accuracy'], label='train_acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('lossval_loss')\n",
    "print(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "386604e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'dense_5')>]\n"
     ]
    }
   ],
   "source": [
    "print(model.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ef0d64ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.33632827e-09, 1.00000000e+00],\n",
       "       [7.81658960e-10, 1.00000000e+00],\n",
       "       [9.03155273e-10, 1.00000000e+00],\n",
       "       [2.95071967e-10, 1.00000000e+00],\n",
       "       [1.06233966e-09, 1.00000000e+00],\n",
       "       [2.69639949e-10, 1.00000000e+00],\n",
       "       [1.16753096e-09, 1.00000000e+00],\n",
       "       [1.19677168e-09, 1.00000000e+00],\n",
       "       [7.90024102e-10, 1.00000000e+00],\n",
       "       [1.41557770e-08, 1.00000000e+00],\n",
       "       [3.48747697e-10, 1.00000000e+00],\n",
       "       [4.38815623e-10, 1.00000000e+00],\n",
       "       [2.94165692e-09, 1.00000000e+00],\n",
       "       [2.37321167e-08, 1.00000000e+00],\n",
       "       [1.17597676e-09, 1.00000000e+00],\n",
       "       [1.49809321e-09, 1.00000000e+00],\n",
       "       [1.18670884e-09, 1.00000000e+00],\n",
       "       [1.58481772e-09, 1.00000000e+00],\n",
       "       [2.33827202e-09, 1.00000000e+00],\n",
       "       [5.03726127e-09, 1.00000000e+00],\n",
       "       [9.74699654e-10, 1.00000000e+00],\n",
       "       [2.20524266e-09, 1.00000000e+00],\n",
       "       [2.99359870e-10, 1.00000000e+00],\n",
       "       [9.66124403e-10, 1.00000000e+00],\n",
       "       [1.83996889e-08, 1.00000000e+00],\n",
       "       [2.55565236e-10, 1.00000000e+00],\n",
       "       [1.84718330e-09, 1.00000000e+00],\n",
       "       [3.29184258e-09, 1.00000000e+00],\n",
       "       [7.08318904e-10, 1.00000000e+00],\n",
       "       [1.78869608e-09, 1.00000000e+00],\n",
       "       [4.92070473e-09, 1.00000000e+00],\n",
       "       [3.11707438e-10, 1.00000000e+00],\n",
       "       [2.01951966e-08, 1.00000000e+00],\n",
       "       [7.63065555e-10, 1.00000000e+00],\n",
       "       [6.23988583e-10, 1.00000000e+00],\n",
       "       [8.57056148e-10, 1.00000000e+00],\n",
       "       [5.26171162e-10, 1.00000000e+00],\n",
       "       [8.41528236e-10, 1.00000000e+00],\n",
       "       [3.90847188e-10, 1.00000000e+00],\n",
       "       [3.90445969e-08, 1.00000000e+00],\n",
       "       [3.82698734e-10, 1.00000000e+00],\n",
       "       [4.97379160e-09, 1.00000000e+00],\n",
       "       [1.00723319e-09, 1.00000000e+00],\n",
       "       [1.21017696e-09, 1.00000000e+00],\n",
       "       [4.92951346e-10, 1.00000000e+00],\n",
       "       [1.71891934e-09, 1.00000000e+00],\n",
       "       [2.88355950e-10, 1.00000000e+00],\n",
       "       [1.18756927e-09, 1.00000000e+00],\n",
       "       [2.62309313e-10, 1.00000000e+00],\n",
       "       [7.77147180e-10, 1.00000000e+00],\n",
       "       [1.03371633e-09, 1.00000000e+00],\n",
       "       [1.28386046e-09, 1.00000000e+00],\n",
       "       [3.19402005e-10, 1.00000000e+00],\n",
       "       [2.47869747e-09, 1.00000000e+00],\n",
       "       [2.64355038e-10, 1.00000000e+00],\n",
       "       [7.24748428e-10, 1.00000000e+00],\n",
       "       [1.05569009e-09, 1.00000000e+00],\n",
       "       [3.74387243e-10, 1.00000000e+00],\n",
       "       [1.45675638e-09, 1.00000000e+00],\n",
       "       [1.22056443e-09, 1.00000000e+00],\n",
       "       [2.86893925e-10, 1.00000000e+00],\n",
       "       [1.17969479e-09, 1.00000000e+00],\n",
       "       [9.55752477e-10, 1.00000000e+00],\n",
       "       [1.43806185e-08, 1.00000000e+00],\n",
       "       [1.20663901e-09, 1.00000000e+00],\n",
       "       [1.07594522e-09, 1.00000000e+00],\n",
       "       [1.31809952e-09, 1.00000000e+00],\n",
       "       [3.96950117e-09, 1.00000000e+00],\n",
       "       [2.06601172e-08, 1.00000000e+00],\n",
       "       [1.23996524e-09, 1.00000000e+00],\n",
       "       [1.32145761e-09, 1.00000000e+00],\n",
       "       [3.50977192e-10, 1.00000000e+00],\n",
       "       [8.88625840e-10, 1.00000000e+00],\n",
       "       [1.85906401e-08, 1.00000000e+00],\n",
       "       [5.63601998e-10, 1.00000000e+00],\n",
       "       [6.92599977e-10, 1.00000000e+00],\n",
       "       [2.72187384e-10, 1.00000000e+00],\n",
       "       [8.30576385e-10, 1.00000000e+00],\n",
       "       [7.76135434e-10, 1.00000000e+00],\n",
       "       [1.44345269e-09, 1.00000000e+00],\n",
       "       [4.21455482e-10, 1.00000000e+00],\n",
       "       [9.20446830e-10, 1.00000000e+00],\n",
       "       [3.98874600e-10, 1.00000000e+00],\n",
       "       [3.06040193e-10, 1.00000000e+00],\n",
       "       [3.24092309e-10, 1.00000000e+00],\n",
       "       [8.65818528e-10, 1.00000000e+00],\n",
       "       [9.00416963e-10, 1.00000000e+00],\n",
       "       [1.05838771e-09, 1.00000000e+00],\n",
       "       [1.23783384e-09, 1.00000000e+00],\n",
       "       [1.65920699e-08, 1.00000000e+00],\n",
       "       [1.23722954e-09, 1.00000000e+00],\n",
       "       [3.21660393e-10, 1.00000000e+00],\n",
       "       [3.42914808e-10, 1.00000000e+00],\n",
       "       [7.59024843e-09, 1.00000000e+00],\n",
       "       [2.47396353e-10, 1.00000000e+00],\n",
       "       [5.01100217e-10, 1.00000000e+00],\n",
       "       [2.59815669e-10, 1.00000000e+00],\n",
       "       [6.59041932e-10, 1.00000000e+00],\n",
       "       [6.97505054e-10, 1.00000000e+00],\n",
       "       [1.99955319e-09, 1.00000000e+00],\n",
       "       [1.37865852e-09, 1.00000000e+00],\n",
       "       [4.00647376e-10, 1.00000000e+00],\n",
       "       [1.27077526e-09, 1.00000000e+00],\n",
       "       [1.77952519e-09, 1.00000000e+00],\n",
       "       [1.44533707e-09, 1.00000000e+00],\n",
       "       [1.13329679e-09, 1.00000000e+00],\n",
       "       [6.31505348e-10, 1.00000000e+00],\n",
       "       [8.33803304e-10, 1.00000000e+00],\n",
       "       [7.03990033e-10, 1.00000000e+00],\n",
       "       [1.80287285e-09, 1.00000000e+00],\n",
       "       [5.76934445e-10, 1.00000000e+00],\n",
       "       [1.05759468e-09, 1.00000000e+00],\n",
       "       [1.24047617e-09, 1.00000000e+00],\n",
       "       [2.05405692e-10, 1.00000000e+00],\n",
       "       [4.17847201e-10, 1.00000000e+00],\n",
       "       [2.87934981e-10, 1.00000000e+00],\n",
       "       [9.18968013e-10, 1.00000000e+00],\n",
       "       [7.22370919e-09, 1.00000000e+00],\n",
       "       [1.29144695e-09, 1.00000000e+00],\n",
       "       [3.85979915e-10, 1.00000000e+00],\n",
       "       [1.13979413e-08, 1.00000000e+00],\n",
       "       [8.57288729e-09, 1.00000000e+00],\n",
       "       [5.35410383e-09, 1.00000000e+00],\n",
       "       [4.09076772e-09, 1.00000000e+00],\n",
       "       [2.49495713e-09, 1.00000000e+00],\n",
       "       [6.60580124e-09, 1.00000000e+00],\n",
       "       [9.04978403e-09, 1.00000000e+00],\n",
       "       [4.48684950e-10, 1.00000000e+00],\n",
       "       [2.48066137e-08, 1.00000000e+00],\n",
       "       [5.48203205e-10, 1.00000000e+00],\n",
       "       [4.94765562e-10, 1.00000000e+00],\n",
       "       [4.14866470e-08, 1.00000000e+00],\n",
       "       [4.16118384e-09, 1.00000000e+00],\n",
       "       [6.92830193e-09, 1.00000000e+00],\n",
       "       [4.75705475e-09, 1.00000000e+00],\n",
       "       [3.65104030e-10, 1.00000000e+00],\n",
       "       [5.59835012e-10, 1.00000000e+00],\n",
       "       [1.21889399e-09, 1.00000000e+00],\n",
       "       [5.51698298e-10, 1.00000000e+00],\n",
       "       [1.05974918e-09, 1.00000000e+00],\n",
       "       [3.55054297e-09, 1.00000000e+00],\n",
       "       [5.17105470e-10, 1.00000000e+00],\n",
       "       [1.55759816e-09, 1.00000000e+00],\n",
       "       [3.26948968e-10, 1.00000000e+00],\n",
       "       [7.56714469e-10, 1.00000000e+00],\n",
       "       [3.56189578e-10, 1.00000000e+00],\n",
       "       [3.73356324e-09, 1.00000000e+00],\n",
       "       [3.25014682e-10, 1.00000000e+00],\n",
       "       [3.75822456e-10, 1.00000000e+00],\n",
       "       [2.27774111e-09, 1.00000000e+00],\n",
       "       [8.03483668e-10, 1.00000000e+00],\n",
       "       [4.94141228e-10, 1.00000000e+00],\n",
       "       [3.71601305e-10, 1.00000000e+00],\n",
       "       [7.39832584e-10, 1.00000000e+00],\n",
       "       [4.87800633e-10, 1.00000000e+00],\n",
       "       [7.85528420e-10, 1.00000000e+00],\n",
       "       [2.79009094e-10, 1.00000000e+00],\n",
       "       [1.98546890e-09, 1.00000000e+00],\n",
       "       [2.06880246e-09, 1.00000000e+00],\n",
       "       [1.09830112e-09, 1.00000000e+00],\n",
       "       [4.26599591e-08, 1.00000000e+00],\n",
       "       [2.93555180e-10, 1.00000000e+00],\n",
       "       [9.30972277e-09, 1.00000000e+00],\n",
       "       [1.36228995e-09, 1.00000000e+00],\n",
       "       [6.82812251e-10, 1.00000000e+00],\n",
       "       [8.61435723e-09, 1.00000000e+00],\n",
       "       [1.13471788e-09, 1.00000000e+00],\n",
       "       [9.57264823e-10, 1.00000000e+00],\n",
       "       [7.32526872e-10, 1.00000000e+00],\n",
       "       [7.74269893e-09, 1.00000000e+00],\n",
       "       [8.16935630e-10, 1.00000000e+00],\n",
       "       [1.48243998e-07, 9.99999881e-01],\n",
       "       [1.59062918e-09, 1.00000000e+00],\n",
       "       [1.81134496e-09, 1.00000000e+00],\n",
       "       [2.96212166e-10, 1.00000000e+00],\n",
       "       [8.41321179e-10, 1.00000000e+00],\n",
       "       [3.51287249e-10, 1.00000000e+00],\n",
       "       [1.88986053e-08, 1.00000000e+00],\n",
       "       [2.56184546e-10, 1.00000000e+00],\n",
       "       [2.41109821e-09, 1.00000000e+00],\n",
       "       [1.00097819e-09, 1.00000000e+00],\n",
       "       [5.96619087e-10, 1.00000000e+00],\n",
       "       [2.23681074e-09, 1.00000000e+00],\n",
       "       [5.28801607e-08, 1.00000000e+00],\n",
       "       [2.83957013e-09, 1.00000000e+00],\n",
       "       [9.19429144e-10, 1.00000000e+00],\n",
       "       [7.14093562e-10, 1.00000000e+00],\n",
       "       [6.26303009e-10, 1.00000000e+00],\n",
       "       [4.94620289e-10, 1.00000000e+00],\n",
       "       [3.55190932e-10, 1.00000000e+00],\n",
       "       [6.88115120e-10, 1.00000000e+00],\n",
       "       [4.06217815e-09, 1.00000000e+00],\n",
       "       [4.45909643e-10, 1.00000000e+00],\n",
       "       [4.13508811e-10, 1.00000000e+00],\n",
       "       [1.14342347e-09, 1.00000000e+00],\n",
       "       [2.03258410e-09, 1.00000000e+00],\n",
       "       [6.39388209e-10, 1.00000000e+00],\n",
       "       [6.50006104e-10, 1.00000000e+00],\n",
       "       [4.92741048e-09, 1.00000000e+00],\n",
       "       [3.91422041e-08, 1.00000000e+00],\n",
       "       [9.68122138e-10, 1.00000000e+00],\n",
       "       [1.70060510e-09, 1.00000000e+00],\n",
       "       [1.93818139e-09, 1.00000000e+00],\n",
       "       [5.84309934e-10, 1.00000000e+00],\n",
       "       [1.25257793e-09, 1.00000000e+00],\n",
       "       [4.15461499e-10, 1.00000000e+00],\n",
       "       [2.57606136e-09, 1.00000000e+00],\n",
       "       [1.02969464e-08, 1.00000000e+00],\n",
       "       [6.83479384e-10, 1.00000000e+00],\n",
       "       [1.04980280e-09, 1.00000000e+00],\n",
       "       [5.30714861e-10, 1.00000000e+00],\n",
       "       [3.52796903e-09, 1.00000000e+00],\n",
       "       [7.19473314e-10, 1.00000000e+00],\n",
       "       [1.06224283e-08, 1.00000000e+00],\n",
       "       [8.41875831e-08, 9.99999881e-01],\n",
       "       [1.27359967e-09, 1.00000000e+00],\n",
       "       [9.82615989e-10, 1.00000000e+00],\n",
       "       [6.98867719e-09, 1.00000000e+00],\n",
       "       [5.24982502e-09, 1.00000000e+00],\n",
       "       [1.40604051e-09, 1.00000000e+00],\n",
       "       [2.25835661e-09, 1.00000000e+00],\n",
       "       [8.08108247e-10, 1.00000000e+00],\n",
       "       [8.31284819e-10, 1.00000000e+00],\n",
       "       [5.68382175e-10, 1.00000000e+00],\n",
       "       [2.00778127e-09, 1.00000000e+00],\n",
       "       [3.83188092e-10, 1.00000000e+00],\n",
       "       [1.68364256e-08, 1.00000000e+00],\n",
       "       [7.29302285e-10, 1.00000000e+00],\n",
       "       [4.80325246e-09, 1.00000000e+00],\n",
       "       [1.04814812e-09, 1.00000000e+00],\n",
       "       [1.08014808e-09, 1.00000000e+00],\n",
       "       [2.22846727e-10, 1.00000000e+00],\n",
       "       [3.12715631e-10, 1.00000000e+00],\n",
       "       [1.34992373e-09, 1.00000000e+00],\n",
       "       [1.00140796e-09, 1.00000000e+00],\n",
       "       [8.96264041e-09, 1.00000000e+00],\n",
       "       [1.18985461e-07, 9.99999881e-01],\n",
       "       [7.27364391e-10, 1.00000000e+00],\n",
       "       [4.36956471e-10, 1.00000000e+00],\n",
       "       [8.57188986e-09, 1.00000000e+00],\n",
       "       [1.48799018e-08, 1.00000000e+00],\n",
       "       [1.40566581e-08, 1.00000000e+00],\n",
       "       [1.82369664e-09, 1.00000000e+00],\n",
       "       [1.77898318e-08, 1.00000000e+00],\n",
       "       [1.34929556e-09, 1.00000000e+00],\n",
       "       [2.64919864e-10, 1.00000000e+00],\n",
       "       [3.27675664e-10, 1.00000000e+00],\n",
       "       [2.39050135e-09, 1.00000000e+00],\n",
       "       [1.65862712e-09, 1.00000000e+00],\n",
       "       [1.17631105e-09, 1.00000000e+00],\n",
       "       [5.12451470e-10, 1.00000000e+00],\n",
       "       [1.23141208e-09, 1.00000000e+00],\n",
       "       [1.12591103e-09, 1.00000000e+00],\n",
       "       [2.10938866e-09, 1.00000000e+00],\n",
       "       [3.68990372e-09, 1.00000000e+00],\n",
       "       [2.09919415e-09, 1.00000000e+00],\n",
       "       [8.63860483e-10, 1.00000000e+00],\n",
       "       [1.47670554e-09, 1.00000000e+00],\n",
       "       [3.51674745e-10, 1.00000000e+00],\n",
       "       [9.18382814e-10, 1.00000000e+00],\n",
       "       [3.92174904e-10, 1.00000000e+00],\n",
       "       [2.11688028e-10, 1.00000000e+00],\n",
       "       [7.30608241e-10, 1.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_generator)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "60bcdc52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "pred = np.argmax(pred, axis=1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "33d47229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('forge_real_signature_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d30286a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('forge_real_signature_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0a7eaa94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "The signature is fraud\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "img = image.load_img('/home/mehdi/Bureau/PI/newdata/real/001001_000.png', target_size=(512,512))\n",
    "x = image.img_to_array(img)\n",
    "x=x/255\n",
    "x=np.expand_dims(x,axis=0)\n",
    "img_data=preprocess_input(x)\n",
    "img_data.shape\n",
    "model.predict(img_data)\n",
    "a=np.argmax(model.predict(img_data), axis=1)\n",
    "print(a)\n",
    "if(a==1):\n",
    "    print(\"The signature is not fraud\")\n",
    "else:\n",
    "    print(\"The signature is fraud\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d104db35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n",
      "The signature is fraud\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3651/1673496510.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mimg_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mimg_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1980\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1981\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1982\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1983\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1984\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for path in checks_geniune:\n",
    "    img = image.load_img(path, target_size=(512,512))\n",
    "    x = image.img_to_array(img)\n",
    "    x=x/255\n",
    "    x=np.expand_dims(x,axis=0)\n",
    "    img_data=preprocess_input(x)\n",
    "    img_data.shape\n",
    "    model.predict(img_data)\n",
    "    a=np.argmax(model.predict(img_data), axis=1)\n",
    "    if(a==1):\n",
    "        print(\"The signature is not fraud\")\n",
    "    else:\n",
    "        print(\"The signature is fraud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a85f0e",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e15e2d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ratio(img):\n",
    "    a = 0\n",
    "    for row in range(len(img)):\n",
    "        for col in range(len(img[0])):\n",
    "            if img[row][col]==True:\n",
    "                a = a+1\n",
    "    total = img.shape[0] * img.shape[1]\n",
    "    return a/total\n",
    "\n",
    "def Centroid(img):\n",
    "    numOfWhites = 0\n",
    "    a = np.array([0,0])\n",
    "    for row in range(len(img)):\n",
    "        for col in range(len(img[0])):\n",
    "            if img[row][col]==True:\n",
    "                b = np.array([row,col])\n",
    "                a = np.add(a,b)\n",
    "                numOfWhites += 1\n",
    "    rowcols = np.array([img.shape[0], img.shape[1]])\n",
    "    centroid = a/numOfWhites\n",
    "    centroid = centroid/rowcols\n",
    "    return centroid[0], centroid[1]\n",
    "\n",
    "def EccentricitySolidity(img):\n",
    "    r = regionprops(img.astype(\"int8\"))\n",
    "    return r[0].eccentricity, r[0].solidity\n",
    "\n",
    "def SkewKurtosis(img):\n",
    "    h,w = img.shape\n",
    "    x = range(w)  # cols value\n",
    "    y = range(h)  # rows value\n",
    "    #calculate projections along the x and y axes\n",
    "    xp = np.sum(img,axis=0)\n",
    "    yp = np.sum(img,axis=1)\n",
    "    #centroid\n",
    "    cx = np.sum(x*xp)/np.sum(xp)\n",
    "    cy = np.sum(y*yp)/np.sum(yp)\n",
    "    #standard deviation\n",
    "    x2 = (x-cx)**2\n",
    "    y2 = (y-cy)**2\n",
    "    sx = np.sqrt(np.sum(x2*xp)/np.sum(img))\n",
    "    sy = np.sqrt(np.sum(y2*yp)/np.sum(img))\n",
    "    \n",
    "    #skewness\n",
    "    x3 = (x-cx)**3\n",
    "    y3 = (y-cy)**3\n",
    "    skewx = np.sum(xp*x3)/(np.sum(img) * sx**3)\n",
    "    skewy = np.sum(yp*y3)/(np.sum(img) * sy**3)\n",
    "\n",
    "    #Kurtosis\n",
    "    x4 = (x-cx)**4\n",
    "    y4 = (y-cy)**4\n",
    "    # 3 is subtracted to calculate relative to the normal distribution\n",
    "    kurtx = np.sum(xp*x4)/(np.sum(img) * sx**4) - 3\n",
    "    kurty = np.sum(yp*y4)/(np.sum(img) * sy**4) - 3\n",
    "\n",
    "    return (skewx , skewy), (kurtx, kurty)\n",
    "\n",
    "def getFeatures(path, img=None, display=False):\n",
    "    if img is None:\n",
    "        img = mpimg.imread(path)\n",
    "    img = preproc(path, display=display)\n",
    "    ratio = Ratio(img)\n",
    "    centroid = Centroid(img)\n",
    "    eccentricity, solidity = EccentricitySolidity(img)\n",
    "    skewness, kurtosis = SkewKurtosis(img)\n",
    "    retVal = (ratio, centroid, eccentricity, solidity, skewness, kurtosis)\n",
    "    return retVal\n",
    "\n",
    "def getCSVFeatures(path, img=None, display=False):\n",
    "    if img is None:\n",
    "        img = mpimg.imread(path)\n",
    "    temp = getFeatures(path, display=display)\n",
    "    features = (temp[0], temp[1][0], temp[1][1], temp[2], temp[3], temp[4][0], temp[4][1], temp[5][0], temp[5][1])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbc9ae7",
   "metadata": {},
   "source": [
    "# Creating And Saving Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "185f6b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making Feature Extraction\n",
    "def makeCSV():\n",
    "    if not(os.path.exists('/home/mehdi/Bureau/PI/Features')):\n",
    "        os.mkdir('/home/mehdi/Bureau/PI/Features')\n",
    "        print('New folder \"Features\" created')\n",
    "    if not(os.path.exists('/home/mehdi/Bureau/PI/Features/Training')):\n",
    "        os.mkdir('/home/mehdi/Bureau/PI/Features/Training')\n",
    "        print('New folder \"Features/Training\" created')\n",
    "    if not(os.path.exists('/home/mehdi/Bureau/PI/Features/Testing')):\n",
    "        os.mkdir('/home/mehdi/Bureau/PI/Features/Testing')\n",
    "        print('New folder \"Features/Testing\" created')\n",
    "    if(len(ForgedDirectory)!=0 and len(GeniuneDirectory)!=0):\n",
    "        print('Forged and Geniune Paths are not empty')\n",
    "    for person in range(1,17):\n",
    "        per = ('00'+str(person))[-3:]\n",
    "        print('Saving features for person id-',per)\n",
    "        totalImage = 0\n",
    "        currentImages=[]\n",
    "        totalImageG = 0\n",
    "        currentImagesG=[]\n",
    "        for path in checks_forged:    \n",
    "            if(path[-10:-7]==str(per)):\n",
    "                totalImage = totalImage + 1\n",
    "                currentImages.append(path)\n",
    "        for pathg in checks_geniune:\n",
    "            if(pathg[-10:-7]==str(per)):\n",
    "                totalImageG = totalImageG + 1\n",
    "                currentImagesG.append(pathg)\n",
    "        print(\"Person :\",per,totalImage,totalImageG)\n",
    "        if(totalImage != 0 and totalImageG !=0):\n",
    "            with open('/home/mehdi/Bureau/PI/Features/Training/training_'+per+'.csv', 'w') as handle:\n",
    "                handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y,output\\n')\n",
    "                if (totalImage!=0):\n",
    "                    for i in range(0,int(totalImage/2)):\n",
    "                        features = getCSVFeatures(currentImages[i])\n",
    "                        handle.write(','.join(map(str, features))+',0\\n')\n",
    "                if (totalImageG != 0):\n",
    "                    for i in range(0,int(totalImageG/2)):\n",
    "                        features = getCSVFeatures(currentImagesG[i])\n",
    "                        handle.write(','.join(map(str, features))+',1\\n')\n",
    "            with open('/home/mehdi/Bureau/PI/Features/Testing/testing'+per+'.csv', 'w') as handle:\n",
    "                handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y,output\\n')\n",
    "                if (totalImage != 0):\n",
    "                    for j in range(int(totalImage/2),totalImage):\n",
    "                        features = getCSVFeatures(currentImages[j])\n",
    "                        handle.write(','.join(map(str, features))+',0\\n')\n",
    "                if (totalImageG != 0):\n",
    "                    for j in range(int(totalImageG/2),totalImageG):\n",
    "                        features = getCSVFeatures(currentImagesG[j])\n",
    "                        handle.write(','.join(map(str, features))+',1\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d56b011a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if((checks_forged[0][-10:-7])==\"013\"):\n",
    "    print('true')\n",
    "int(6/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9ca398b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forged and Geniune Paths are not empty\n",
      "Saving features for person id- 001\n",
      "Person : 001 8 24\n",
      "Saving features for person id- 002\n",
      "Person : 002 12 24\n",
      "Saving features for person id- 003\n",
      "Person : 003 12 24\n",
      "Saving features for person id- 004\n",
      "Person : 004 11 24\n",
      "Saving features for person id- 005\n",
      "Person : 005 0 0\n",
      "Saving features for person id- 006\n",
      "Person : 006 12 24\n",
      "Saving features for person id- 007\n",
      "Person : 007 0 0\n",
      "Saving features for person id- 008\n",
      "Person : 008 0 0\n",
      "Saving features for person id- 009\n",
      "Person : 009 12 24\n",
      "Saving features for person id- 010\n",
      "Person : 010 0 0\n",
      "Saving features for person id- 011\n",
      "Person : 011 0 0\n",
      "Saving features for person id- 012\n",
      "Person : 012 12 24\n",
      "Saving features for person id- 013\n",
      "Person : 013 0 0\n",
      "Saving features for person id- 014\n",
      "Person : 014 16 24\n",
      "Saving features for person id- 015\n",
      "Person : 015 12 24\n",
      "Saving features for person id- 016\n",
      "Person : 016 16 23\n"
     ]
    }
   ],
   "source": [
    "makeCSV()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5115d003",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f84670d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(path):\n",
    "    feature = getCSVFeatures(path)\n",
    "    if not(os.path.exists('/home/mehdi/Bureau/PI/TestFeatures')):\n",
    "        os.mkdir('/home/mehdi/Bureau/PI/TestFeatures')\n",
    "    with open('/home/mehdi/Bureau/PI/TestFeatures/testcsv.csv', 'w') as handle:\n",
    "        handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y\\n')\n",
    "        handle.write(','.join(map(str, feature))+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7a09959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(train_path, test_path, type2=False):\n",
    "    # Reading train data\n",
    "    df = pd.read_csv(train_path, usecols=range(n_input))\n",
    "    train_input = np.array(df.values)\n",
    "    train_input = train_input.astype(np.float32, copy=False)  # Converting input to float_32\n",
    "    df = pd.read_csv(train_path, usecols=(n_input,))\n",
    "    temp = [elem[0] for elem in df.values]\n",
    "    correct = np.array(temp)\n",
    "    corr_train = keras.utils.np_utils.to_categorical(correct,2)      # Converting to one hot\n",
    "    # Reading test data\n",
    "    df = pd.read_csv(test_path, usecols=range(n_input))\n",
    "    test_input = np.array(df.values)\n",
    "    test_input = test_input.astype(np.float32, copy=False)\n",
    "    if not(type2):\n",
    "        df = pd.read_csv(test_path, usecols=(n_input,))\n",
    "        temp = [elem[0] for elem in df.values]\n",
    "        correct = np.array(temp)\n",
    "        corr_test = kearas.utils.to_categorical(correct,2)      # Converting to one hot\n",
    "    if not(type2):\n",
    "        return train_input, corr_train, test_input, corr_test\n",
    "    else:\n",
    "        return train_input, corr_train, test_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3075c667",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 9\n",
    "#train_person_id = input(\"Enter person's id : \")\n",
    "#test_image_path = input(\"Enter path of signature image : \")\n",
    "\n",
    "test_image_path=\"/home/mehdi/Bureau/PI/TrainingSet/Offline_Genuine/001_02.PNG\"\n",
    "#train_path = '/home/mehdi/Bureau/PI/Features/Training/training_00'+train_person_id+'.csv'\n",
    "train_path = '/home/mehdi/Bureau/PI/Features/Training/training_001.csv'\n",
    "testing(test_image_path)\n",
    "test_path = '/home/mehdi/Bureau/PI/TestFeatures/testcsv.csv'\n",
    "ops.reset_default_graph()\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 1000\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 7 # 1st layer number of neurons\n",
    "n_hidden_2 = 10 # 2nd layer number of neurons\n",
    "n_hidden_3 = 30 # 3rd layer\n",
    "n_classes = 2 # no. of classes (genuine or forged)\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.compat.v1.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.compat.v1.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random.normal([n_input, n_hidden_1], seed=1)),\n",
    "    'h2': tf.Variable(tf.random.normal([n_hidden_1, n_hidden_2])),\n",
    "    'h3': tf.Variable(tf.random.normal([n_hidden_2, n_hidden_3])),\n",
    "    'out': tf.Variable(tf.random.normal([n_hidden_1, n_classes], seed=2))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random.normal([n_hidden_1], seed=3)),\n",
    "    'b2': tf.Variable(tf.random.normal([n_hidden_2])),\n",
    "    'b3': tf.Variable(tf.random.normal([n_hidden_3])),\n",
    "    'out': tf.Variable(tf.random.normal([n_classes], seed=4))\n",
    "}\n",
    "\n",
    "# Create model\n",
    "def multilayer_perceptron(x):\n",
    "    layer_1 = tf.tanh((tf.matmul(x, weights['h1']) + biases['b1']))\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
    "    out_layer = tf.tanh(tf.matmul(layer_1, weights['out']) + biases['out'])\n",
    "    return out_layer\n",
    "\n",
    "# Construct model\n",
    "logits = multilayer_perceptron(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a3c5e9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.compat.v1.squared_difference(logits, Y))\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "var1 = tf.Variable(1000.0)\n",
    "loss = lambda: (var1 ** 2)/2.0 \n",
    "train_op = optimizer.minimize(loss,[var1])\n",
    "\n",
    "\n",
    "# For accuracies\n",
    "pred = tf.nn.softmax(logits)  # Apply softmax to logits\n",
    "correct_prediction = tf.equal(tf.argmax(pred,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "# Initializing the variables\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "#var_list=None,tape=tf.GradientTape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9919719a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(train_path, test_path, type2=False):   \n",
    "    if not(type2):\n",
    "        train_input, corr_train, test_input, corr_test = readCSV(train_path, test_path)\n",
    "    else:\n",
    "        train_input, corr_train, test_input = readCSV(train_path, test_path, type2)\n",
    "    ans = 'Random'\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        sess.run(init)\n",
    "        # Training cycle\n",
    "        for epoch in range(training_epochs):\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, cost = sess.run([train_op, loss_op], feed_dict={X: train_input, Y: corr_train})\n",
    "            if cost<0.0001:\n",
    "                break\n",
    "#             # Display logs per epoch step\n",
    "#             if epoch % 999 == 0:\n",
    "#                 print(\"Epoch:\", '%04d' % (epoch+1), \"cost={:.9f}\".format(cost))\n",
    "#         print(\"Optimization Finished!\")\n",
    "        \n",
    "        # Finding accuracies\n",
    "        accuracy1 =  accuracy.eval({X: train_input, Y: corr_train})\n",
    "#         print(\"Accuracy for train:\", accuracy1)\n",
    "#         print(\"Accuracy for test:\", accuracy2)\n",
    "        if type2 is False:\n",
    "            accuracy2 =  accuracy.eval({X: test_input, Y: corr_test})\n",
    "            return accuracy1, accuracy2\n",
    "        else:\n",
    "            prediction = pred.eval({X: test_input})\n",
    "            if prediction[0][1]>prediction[0][0]:\n",
    "                print('Genuine Image')\n",
    "                return True\n",
    "            else:\n",
    "                print('Forged Image')\n",
    "                return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "225eb9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndTest(rate=0.001, epochs=1700, neurons=7, display=False):    \n",
    "    start = time()\n",
    "\n",
    "    # Parameters\n",
    "    global training_rate, training_epochs, n_hidden_1\n",
    "    learning_rate = rate\n",
    "    training_epochs = epochs\n",
    "\n",
    "    # Network Parameters\n",
    "    n_hidden_1 = neurons # 1st layer number of neurons\n",
    "    n_hidden_2 = 7 # 2nd layer number of neurons\n",
    "    n_hidden_3 = 30 # 3rd layer\n",
    "\n",
    "    train_avg, test_avg = 0, 0\n",
    "    n = 10\n",
    "    for i in range(1,n+1):\n",
    "        if display:\n",
    "            print(\"Running for Person id\",i)\n",
    "        temp = ('0'+str(i))[-2:]\n",
    "        train_score, test_score = evaluate(train_path.replace('01',temp), test_path.replace('01',temp))\n",
    "        train_avg += train_score\n",
    "        test_avg += test_score\n",
    "    if display:\n",
    "#         print(\"Number of neurons in Hidden layer-\", n_hidden_1)\n",
    "        print(\"Training average-\", train_avg/n)\n",
    "        print(\"Testing average-\", test_avg/n)\n",
    "        print(\"Time taken-\", time()-start)\n",
    "    return train_avg/n, test_avg/n, (time()-start)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7f6eeb17",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forged Image\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(train_path, test_path, type2=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79e6aba",
   "metadata": {},
   "source": [
    "# Using ORB FAST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b681d5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2 \n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.io as sio\n",
    "import sys\n",
    "import numpy as np\n",
    "import platform\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a51862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_FAST(source):\n",
    "    #here fast is only used for detecting the keypoints but later on BRIEF will be used for the \n",
    "    img = cv2.imread(source,0)     \n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    #kp1, des1 = orb.detectAndCompute(img1,None)\n",
    "    #kp2, des2 = orb.detectAndCompute(img2,None)   \n",
    "    # Initiate FAST extractor\n",
    "    #fast = cv2.FastFeatureDetector_create()\n",
    "    #kp = fast.detect(img,None)\n",
    "    orb = cv2.xfeatures2d.SIFT_create()\n",
    "    kp = orb.detect(img, None)\n",
    "    # Initiate BRIEF extractor\n",
    "    #brief = cv2.xfeatures2d.BriefDescriptorExtractor_create()\n",
    "    #kp1, des1 = brief.compute(img, kp)\n",
    "    kp1, des1 = orb.compute(img, kp)\n",
    "    return kp1, des1\n",
    "def MATCH_CUSTOM(input1, input2):\n",
    "    name = input1.split(\"_\")\n",
    "    number_of_matches = 20;       \n",
    "    k1, d1 = apply_FAST(input1)\n",
    "    k2, d2 = apply_FAST(input2)\n",
    "    \n",
    "  \n",
    "    \n",
    "    #print(\"Feature Lengths\", len(k1), len(k2))\n",
    "    # create BFMatcher object\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "    # Match descriptors.\n",
    "    #matches = bf.match(d1,d2)\n",
    "    matches = bf.knnMatch(d1,d2, k=2)\n",
    "    # Sort them in the order of their distance.\n",
    "    #matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Apply ratio test\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good.append([m])\n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "   \n",
    "        \n",
    "    #print(\"Good Length: \", len(good))\n",
    "    print(\"For entry \", name[0],\"between\", input1, \"and \", input2,\" Feature Lengths\", len(k1), len(k2), \"Maches : \", len(good))\n",
    "    return len(good)\n",
    "    \n",
    "    #img1 = cv2.imread(input1,0)\n",
    "    #img2 = cv2.imread(input2,0)\n",
    "    #img3 = cv2.drawMatches(img1,k1,img2,k2, matches[:number_of_matches] ,None, flags=2)\n",
    "    #img3 = cv2.drawMatchesKnn(img1,k1,img2,k2,good,None, flags=2)\n",
    "    #plt.imshow(img3),plt.show()\n",
    "\n",
    "\n",
    "#Function to get the list of files in a supplied directory\n",
    "def files(path):  \n",
    "    for file in os.listdir(path):\n",
    "        if os.path.isfile(os.path.join(path, file)):\n",
    "            yield file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "686dbbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.11 (default, Jul 27 2021, 14:32:16) \n",
      "[GCC 7.5.0]\n",
      "['21_013.PNG', '17_013.PNG', '19_013.PNG', '20_013.PNG', '18_013.PNG', '23_013.PNG', '15_013.PNG', '13_013.PNG', '14_013.PNG', '22_013.PNG', '16_013.PNG', '24_013.PNG']\n",
      "For entry  050 between 050_Renfrenced/21_013.PNG and  050_Renfrenced/17_013.PNG  Feature Lengths 531 542 Maches :  28\n",
      "For entry  050 between 050_Renfrenced/21_013.PNG and  050_Renfrenced/19_013.PNG  Feature Lengths 531 456 Maches :  26\n",
      "For entry  050 between 050_Renfrenced/21_013.PNG and  050_Renfrenced/20_013.PNG  Feature Lengths 531 533 Maches :  33\n",
      "For entry  050 between 050_Renfrenced/21_013.PNG and  050_Renfrenced/18_013.PNG  Feature Lengths 531 451 Maches :  29\n",
      "For entry  050 between 050_Renfrenced/21_013.PNG and  050_Renfrenced/23_013.PNG  Feature Lengths 531 450 Maches :  33\n",
      "For entry  050 between 050_Renfrenced/21_013.PNG and  050_Renfrenced/15_013.PNG  Feature Lengths 531 542 Maches :  41\n",
      "For entry  050 between 050_Renfrenced/21_013.PNG and  050_Renfrenced/13_013.PNG  Feature Lengths 531 461 Maches :  43\n",
      "For entry  050 between 050_Renfrenced/21_013.PNG and  050_Renfrenced/14_013.PNG  Feature Lengths 531 478 Maches :  49\n",
      "For entry  050 between 050_Renfrenced/21_013.PNG and  050_Renfrenced/22_013.PNG  Feature Lengths 531 547 Maches :  24\n",
      "For entry  050 between 050_Renfrenced/21_013.PNG and  050_Renfrenced/16_013.PNG  Feature Lengths 531 506 Maches :  54\n",
      "For entry  050 between 050_Renfrenced/21_013.PNG and  050_Renfrenced/24_013.PNG  Feature Lengths 531 491 Maches :  41\n",
      "For entry  050 between 050_Renfrenced/17_013.PNG and  050_Renfrenced/19_013.PNG  Feature Lengths 542 456 Maches :  33\n",
      "For entry  050 between 050_Renfrenced/17_013.PNG and  050_Renfrenced/20_013.PNG  Feature Lengths 542 533 Maches :  30\n",
      "For entry  050 between 050_Renfrenced/17_013.PNG and  050_Renfrenced/18_013.PNG  Feature Lengths 542 451 Maches :  33\n",
      "For entry  050 between 050_Renfrenced/17_013.PNG and  050_Renfrenced/23_013.PNG  Feature Lengths 542 450 Maches :  44\n",
      "For entry  050 between 050_Renfrenced/17_013.PNG and  050_Renfrenced/15_013.PNG  Feature Lengths 542 542 Maches :  42\n",
      "For entry  050 between 050_Renfrenced/17_013.PNG and  050_Renfrenced/13_013.PNG  Feature Lengths 542 461 Maches :  34\n",
      "For entry  050 between 050_Renfrenced/17_013.PNG and  050_Renfrenced/14_013.PNG  Feature Lengths 542 478 Maches :  36\n",
      "For entry  050 between 050_Renfrenced/17_013.PNG and  050_Renfrenced/22_013.PNG  Feature Lengths 542 547 Maches :  40\n",
      "For entry  050 between 050_Renfrenced/17_013.PNG and  050_Renfrenced/16_013.PNG  Feature Lengths 542 506 Maches :  40\n",
      "For entry  050 between 050_Renfrenced/17_013.PNG and  050_Renfrenced/24_013.PNG  Feature Lengths 542 491 Maches :  33\n",
      "For entry  050 between 050_Renfrenced/19_013.PNG and  050_Renfrenced/20_013.PNG  Feature Lengths 456 533 Maches :  27\n",
      "For entry  050 between 050_Renfrenced/19_013.PNG and  050_Renfrenced/18_013.PNG  Feature Lengths 456 451 Maches :  28\n",
      "For entry  050 between 050_Renfrenced/19_013.PNG and  050_Renfrenced/23_013.PNG  Feature Lengths 456 450 Maches :  37\n",
      "For entry  050 between 050_Renfrenced/19_013.PNG and  050_Renfrenced/15_013.PNG  Feature Lengths 456 542 Maches :  25\n",
      "For entry  050 between 050_Renfrenced/19_013.PNG and  050_Renfrenced/13_013.PNG  Feature Lengths 456 461 Maches :  42\n",
      "For entry  050 between 050_Renfrenced/19_013.PNG and  050_Renfrenced/14_013.PNG  Feature Lengths 456 478 Maches :  37\n",
      "For entry  050 between 050_Renfrenced/19_013.PNG and  050_Renfrenced/22_013.PNG  Feature Lengths 456 547 Maches :  30\n",
      "For entry  050 between 050_Renfrenced/19_013.PNG and  050_Renfrenced/16_013.PNG  Feature Lengths 456 506 Maches :  28\n",
      "For entry  050 between 050_Renfrenced/19_013.PNG and  050_Renfrenced/24_013.PNG  Feature Lengths 456 491 Maches :  31\n",
      "For entry  050 between 050_Renfrenced/20_013.PNG and  050_Renfrenced/18_013.PNG  Feature Lengths 533 451 Maches :  28\n",
      "For entry  050 between 050_Renfrenced/20_013.PNG and  050_Renfrenced/23_013.PNG  Feature Lengths 533 450 Maches :  47\n",
      "For entry  050 between 050_Renfrenced/20_013.PNG and  050_Renfrenced/15_013.PNG  Feature Lengths 533 542 Maches :  30\n",
      "For entry  050 between 050_Renfrenced/20_013.PNG and  050_Renfrenced/13_013.PNG  Feature Lengths 533 461 Maches :  43\n",
      "For entry  050 between 050_Renfrenced/20_013.PNG and  050_Renfrenced/14_013.PNG  Feature Lengths 533 478 Maches :  32\n",
      "For entry  050 between 050_Renfrenced/20_013.PNG and  050_Renfrenced/22_013.PNG  Feature Lengths 533 547 Maches :  39\n",
      "For entry  050 between 050_Renfrenced/20_013.PNG and  050_Renfrenced/16_013.PNG  Feature Lengths 533 506 Maches :  35\n",
      "For entry  050 between 050_Renfrenced/20_013.PNG and  050_Renfrenced/24_013.PNG  Feature Lengths 533 491 Maches :  38\n",
      "For entry  050 between 050_Renfrenced/18_013.PNG and  050_Renfrenced/23_013.PNG  Feature Lengths 451 450 Maches :  33\n",
      "For entry  050 between 050_Renfrenced/18_013.PNG and  050_Renfrenced/15_013.PNG  Feature Lengths 451 542 Maches :  34\n",
      "For entry  050 between 050_Renfrenced/18_013.PNG and  050_Renfrenced/13_013.PNG  Feature Lengths 451 461 Maches :  40\n",
      "For entry  050 between 050_Renfrenced/18_013.PNG and  050_Renfrenced/14_013.PNG  Feature Lengths 451 478 Maches :  29\n",
      "For entry  050 between 050_Renfrenced/18_013.PNG and  050_Renfrenced/22_013.PNG  Feature Lengths 451 547 Maches :  27\n",
      "For entry  050 between 050_Renfrenced/18_013.PNG and  050_Renfrenced/16_013.PNG  Feature Lengths 451 506 Maches :  34\n",
      "For entry  050 between 050_Renfrenced/18_013.PNG and  050_Renfrenced/24_013.PNG  Feature Lengths 451 491 Maches :  37\n",
      "For entry  050 between 050_Renfrenced/23_013.PNG and  050_Renfrenced/15_013.PNG  Feature Lengths 450 542 Maches :  30\n",
      "For entry  050 between 050_Renfrenced/23_013.PNG and  050_Renfrenced/13_013.PNG  Feature Lengths 450 461 Maches :  28\n",
      "For entry  050 between 050_Renfrenced/23_013.PNG and  050_Renfrenced/14_013.PNG  Feature Lengths 450 478 Maches :  39\n",
      "For entry  050 between 050_Renfrenced/23_013.PNG and  050_Renfrenced/22_013.PNG  Feature Lengths 450 547 Maches :  35\n",
      "For entry  050 between 050_Renfrenced/23_013.PNG and  050_Renfrenced/16_013.PNG  Feature Lengths 450 506 Maches :  28\n",
      "For entry  050 between 050_Renfrenced/23_013.PNG and  050_Renfrenced/24_013.PNG  Feature Lengths 450 491 Maches :  41\n",
      "For entry  050 between 050_Renfrenced/15_013.PNG and  050_Renfrenced/13_013.PNG  Feature Lengths 542 461 Maches :  40\n",
      "For entry  050 between 050_Renfrenced/15_013.PNG and  050_Renfrenced/14_013.PNG  Feature Lengths 542 478 Maches :  36\n",
      "For entry  050 between 050_Renfrenced/15_013.PNG and  050_Renfrenced/22_013.PNG  Feature Lengths 542 547 Maches :  31\n",
      "For entry  050 between 050_Renfrenced/15_013.PNG and  050_Renfrenced/16_013.PNG  Feature Lengths 542 506 Maches :  31\n",
      "For entry  050 between 050_Renfrenced/15_013.PNG and  050_Renfrenced/24_013.PNG  Feature Lengths 542 491 Maches :  55\n",
      "For entry  050 between 050_Renfrenced/13_013.PNG and  050_Renfrenced/14_013.PNG  Feature Lengths 461 478 Maches :  33\n",
      "For entry  050 between 050_Renfrenced/13_013.PNG and  050_Renfrenced/22_013.PNG  Feature Lengths 461 547 Maches :  29\n",
      "For entry  050 between 050_Renfrenced/13_013.PNG and  050_Renfrenced/16_013.PNG  Feature Lengths 461 506 Maches :  30\n",
      "For entry  050 between 050_Renfrenced/13_013.PNG and  050_Renfrenced/24_013.PNG  Feature Lengths 461 491 Maches :  27\n",
      "For entry  050 between 050_Renfrenced/14_013.PNG and  050_Renfrenced/22_013.PNG  Feature Lengths 478 547 Maches :  40\n",
      "For entry  050 between 050_Renfrenced/14_013.PNG and  050_Renfrenced/16_013.PNG  Feature Lengths 478 506 Maches :  36\n",
      "For entry  050 between 050_Renfrenced/14_013.PNG and  050_Renfrenced/24_013.PNG  Feature Lengths 478 491 Maches :  38\n",
      "For entry  050 between 050_Renfrenced/22_013.PNG and  050_Renfrenced/16_013.PNG  Feature Lengths 547 506 Maches :  26\n",
      "For entry  050 between 050_Renfrenced/22_013.PNG and  050_Renfrenced/24_013.PNG  Feature Lengths 547 491 Maches :  34\n",
      "For entry  050 between 050_Renfrenced/16_013.PNG and  050_Renfrenced/24_013.PNG  Feature Lengths 506 491 Maches :  38\n",
      "[28, 26, 33, 29, 33, 41, 43, 49, 24, 54, 41, 33, 30, 33, 44, 42, 34, 36, 40, 40, 33, 27, 28, 37, 25, 42, 37, 30, 28, 31, 28, 47, 30, 43, 32, 39, 35, 38, 33, 34, 40, 29, 27, 34, 37, 30, 28, 39, 35, 28, 41, 40, 36, 31, 31, 55, 33, 29, 30, 27, 40, 36, 38, 26, 34, 38]\n",
      "[[0, 1, 28], [0, 2, 26], [0, 3, 33], [0, 4, 29], [0, 5, 33], [0, 6, 41], [0, 7, 43], [0, 8, 49], [0, 9, 24], [0, 10, 54], [0, 11, 41], [1, 2, 33], [1, 3, 30], [1, 4, 33], [1, 5, 44], [1, 6, 42], [1, 7, 34], [1, 8, 36], [1, 9, 40], [1, 10, 40], [1, 11, 33], [2, 3, 27], [2, 4, 28], [2, 5, 37], [2, 6, 25], [2, 7, 42], [2, 8, 37], [2, 9, 30], [2, 10, 28], [2, 11, 31], [3, 4, 28], [3, 5, 47], [3, 6, 30], [3, 7, 43], [3, 8, 32], [3, 9, 39], [3, 10, 35], [3, 11, 38], [4, 5, 33], [4, 6, 34], [4, 7, 40], [4, 8, 29], [4, 9, 27], [4, 10, 34], [4, 11, 37], [5, 6, 30], [5, 7, 28], [5, 8, 39], [5, 9, 35], [5, 10, 28], [5, 11, 41], [6, 7, 40], [6, 8, 36], [6, 9, 31], [6, 10, 31], [6, 11, 55], [7, 8, 33], [7, 9, 29], [7, 10, 30], [7, 11, 27], [8, 9, 40], [8, 10, 36], [8, 11, 38], [9, 10, 26], [9, 11, 34], [10, 11, 38]]\n",
      "15_013.PNG\n",
      "Std dev:6\n",
      "Mean34\n",
      " \n",
      "\n",
      " _______________________Training Stage ends here______________________\n",
      "\n",
      "\n",
      "\n",
      "['10_013.png', '11_013.png', '01_0113013.PNG', '02_0203013.PNG', '04_0113013.PNG', '01_013.png', '02_0204013.PNG', '02_0113013.PNG', '03_013.png', '04_0203013.PNG', '05_013.png', '09_013.png', '03_0204013.PNG', '06_013.png', '12_013.png', '04_0204013.PNG', '01_0204013.PNG', '01_0203013.PNG', '03_0203013.PNG', '02_013.png', '08_013.png', '07_013.png', '04_013.png', '03_0113013.PNG']\n",
      "For entry  050 between 050_Questioned/10_013.png and  050_Renfrenced/15_013.PNG  Feature Lengths 477 542 Maches :  40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For entry  050 between 050_Questioned/11_013.png and  050_Renfrenced/15_013.PNG  Feature Lengths 494 542 Maches :  33\n",
      "For entry  050 between 050_Questioned/01_0113013.PNG and  050_Renfrenced/15_013.PNG  Feature Lengths 504 542 Maches :  35\n",
      "For entry  050 between 050_Questioned/02_0203013.PNG and  050_Renfrenced/15_013.PNG  Feature Lengths 675 542 Maches :  33\n",
      "For entry  050 between 050_Questioned/04_0113013.PNG and  050_Renfrenced/15_013.PNG  Feature Lengths 646 542 Maches :  29\n",
      "For entry  050 between 050_Questioned/01_013.png and  050_Renfrenced/15_013.PNG  Feature Lengths 503 542 Maches :  29\n",
      "For entry  050 between 050_Questioned/02_0204013.PNG and  050_Renfrenced/15_013.PNG  Feature Lengths 510 542 Maches :  30\n",
      "For entry  050 between 050_Questioned/02_0113013.PNG and  050_Renfrenced/15_013.PNG  Feature Lengths 683 542 Maches :  25\n",
      "For entry  050 between 050_Questioned/03_013.png and  050_Renfrenced/15_013.PNG  Feature Lengths 505 542 Maches :  31\n",
      "For entry  050 between 050_Questioned/04_0203013.PNG and  050_Renfrenced/15_013.PNG  Feature Lengths 612 542 Maches :  37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For entry  050 between 050_Questioned/05_013.png and  050_Renfrenced/15_013.PNG  Feature Lengths 467 542 Maches :  36\n",
      "For entry  050 between 050_Questioned/09_013.png and  050_Renfrenced/15_013.PNG  Feature Lengths 528 542 Maches :  29\n",
      "For entry  050 between 050_Questioned/03_0204013.PNG and  050_Renfrenced/15_013.PNG  Feature Lengths 467 542 Maches :  27\n",
      "For entry  050 between 050_Questioned/06_013.png and  050_Renfrenced/15_013.PNG  Feature Lengths 492 542 Maches :  29\n",
      "For entry  050 between 050_Questioned/12_013.png and  050_Renfrenced/15_013.PNG  Feature Lengths 408 542 Maches :  16\n",
      "For entry  050 between 050_Questioned/04_0204013.PNG and  050_Renfrenced/15_013.PNG  Feature Lengths 506 542 Maches :  21\n",
      "For entry  050 between 050_Questioned/01_0204013.PNG and  050_Renfrenced/15_013.PNG  Feature Lengths 314 542 Maches :  13\n",
      "For entry  050 between 050_Questioned/01_0203013.PNG and  050_Renfrenced/15_013.PNG  Feature Lengths 577 542 Maches :  34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For entry  050 between 050_Questioned/03_0203013.PNG and  050_Renfrenced/15_013.PNG  Feature Lengths 660 542 Maches :  32\n",
      "For entry  050 between 050_Questioned/02_013.png and  050_Renfrenced/15_013.PNG  Feature Lengths 589 542 Maches :  28\n",
      "For entry  050 between 050_Questioned/08_013.png and  050_Renfrenced/15_013.PNG  Feature Lengths 460 542 Maches :  35\n",
      "For entry  050 between 050_Questioned/07_013.png and  050_Renfrenced/15_013.PNG  Feature Lengths 531 542 Maches :  43\n",
      "For entry  050 between 050_Questioned/04_013.png and  050_Renfrenced/15_013.PNG  Feature Lengths 479 542 Maches :  36\n",
      "For entry  050 between 050_Questioned/03_0113013.PNG and  050_Renfrenced/15_013.PNG  Feature Lengths 629 542 Maches :  30\n",
      "TP = 11 FN = 1\n",
      "FP = 10 TN = 2\n",
      "Accuracy : 0.5416666666666666\n",
      "Precision: 0.5238095238095238\n",
      "Recall   : 0.9166666666666666\n",
      "F-measure: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "print(sys.version)\n",
    "platform.python_version()\n",
    "PWD1 = \"050_Renfrenced\"\n",
    "entries = list()\n",
    "file_list = files(PWD1)\n",
    "for file in file_list:\n",
    "    if \"PNG\" in file:\n",
    "        #print(file)\n",
    "        entries.append(file)\n",
    "print(entries)\n",
    "\n",
    "\n",
    "\n",
    "#Training Stage\n",
    "match_values = list()\n",
    "number_of_entries = len(entries)\n",
    "data = list()\n",
    "for i in range(0, number_of_entries):\n",
    "    for j in range(i+1, number_of_entries):\n",
    "        #print(i, j)\n",
    "        match_values.append(MATCH_CUSTOM(PWD1 + \"/\" + entries[i],PWD1 + \"/\" +  entries[j]))\n",
    "        data.append([i,j,match_values[len(match_values)-1]])\n",
    "print(match_values)\n",
    "print(data)\n",
    "\n",
    "mean_ = int(sum(match_values)/len(match_values))\n",
    "std_dev = int(statistics.stdev(match_values))\n",
    "\n",
    "diff = -1;\n",
    "reference = None\n",
    "index = -5\n",
    "mean_new = -5\n",
    "for x in range(0, len(match_values)):\n",
    "    if match_values[x] > diff:\n",
    "        diff = match_values[x]\n",
    "        reference = entries[data[x][0]]\n",
    "        index = x       \n",
    "print(reference)\n",
    "print(\"Std dev:\" +str(std_dev))\n",
    "print(\"Mean\" + str(mean_) + \"\\n \\n\\n _______________________Training Stage ends here______________________\\n\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#TestingStage\n",
    "#Confustion_Matrix_base\n",
    "TP_true_positive  = 0\n",
    "FN_false_negative = 0\n",
    "FP_false_positive = 0\n",
    "TN_true_negative  = 0\n",
    "\n",
    "\n",
    "PWD2 = \"050_Questioned\"\n",
    "entries = list()\n",
    "file_list = files(PWD2)\n",
    "for file in file_list:\n",
    "    if \"PNG\" in file:\n",
    "        #print(file)\n",
    "        #actual_class_false +=1\n",
    "        entries.append(file)\n",
    "    if \"png\" in file:\n",
    "        #print(file)\n",
    "        #actual_class_true +=1\n",
    "        entries.append(file)\n",
    "print(entries)\n",
    "\n",
    "for x in entries:\n",
    "    match_count = MATCH_CUSTOM(PWD2 + \"/\" + x ,PWD1 + \"/\" +  reference)\n",
    "    if len(x) == 10:\n",
    "        if abs(match_count-mean_) < std_dev*2:\n",
    "            TP_true_positive += 1\n",
    "        else:\n",
    "            FN_false_negative += 1\n",
    "    else:\n",
    "        if abs(match_count-mean_) < std_dev*2:\n",
    "            FP_false_positive +=1\n",
    "        else:\n",
    "            TN_true_negative +=1\n",
    "\n",
    "print(\"TP = \" + str(TP_true_positive) + \" FN = \" + str(FN_false_negative) )\n",
    "print(\"FP = \" + str(FP_false_positive) + \" TN = \" + str(TN_true_negative) )\n",
    "\n",
    "accuracy = (TP_true_positive+ TN_true_negative)/24\n",
    "precision = TP_true_positive/(TP_true_positive+FP_false_positive)\n",
    "recall = TP_true_positive / (TP_true_positive + FN_false_negative)\n",
    "f_measure = 2 / (1/precision+1/recall)\n",
    "\n",
    "print(\"Accuracy : \" + str ( accuracy))   \n",
    "print(\"Precision: \" + str(precision))\n",
    "print(\"Recall   : \" + str(recall))\n",
    "print(\"F-measure: \" + str(f_measure))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773eea6b",
   "metadata": {},
   "source": [
    "# ORB FAST Brief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ecb73cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.11 (default, Jul 27 2021, 14:32:16) \n",
      "[GCC 7.5.0]\n",
      "['21_013.PNG', '17_013.PNG', '19_013.PNG', '20_013.PNG', '18_013.PNG', '23_013.PNG', '15_013.PNG', '13_013.PNG', '14_013.PNG', '22_013.PNG', '16_013.PNG', '24_013.PNG']\n",
      "[4, 1, 1, 3, 7, 5, 4, 3, 3, 4, 8, 4, 1, 5, 1, 9, 2, 5, 8, 6, 2, 4, 5, 5, 3, 4, 13, 7, 7, 4, 3, 3, 2, 4, 2, 4, 5, 2, 1, 4, 3, 2, 3, 1, 5, 2, 3, 2, 8, 1, 6, 4, 2, 2, 0, 2, 4, 6, 6, 3, 3, 2, 4, 7, 3, 2]\n",
      "[[0, 1, 4], [0, 2, 1], [0, 3, 1], [0, 4, 3], [0, 5, 7], [0, 6, 5], [0, 7, 4], [0, 8, 3], [0, 9, 3], [0, 10, 4], [0, 11, 8], [1, 2, 4], [1, 3, 1], [1, 4, 5], [1, 5, 1], [1, 6, 9], [1, 7, 2], [1, 8, 5], [1, 9, 8], [1, 10, 6], [1, 11, 2], [2, 3, 4], [2, 4, 5], [2, 5, 5], [2, 6, 3], [2, 7, 4], [2, 8, 13], [2, 9, 7], [2, 10, 7], [2, 11, 4], [3, 4, 3], [3, 5, 3], [3, 6, 2], [3, 7, 4], [3, 8, 2], [3, 9, 4], [3, 10, 5], [3, 11, 2], [4, 5, 1], [4, 6, 4], [4, 7, 3], [4, 8, 2], [4, 9, 3], [4, 10, 1], [4, 11, 5], [5, 6, 2], [5, 7, 3], [5, 8, 2], [5, 9, 8], [5, 10, 1], [5, 11, 6], [6, 7, 4], [6, 8, 2], [6, 9, 2], [6, 10, 0], [6, 11, 2], [7, 8, 4], [7, 9, 6], [7, 10, 6], [7, 11, 3], [8, 9, 3], [8, 10, 2], [8, 11, 4], [9, 10, 7], [9, 11, 3], [10, 11, 2]]\n",
      "19_013.PNG\n",
      "3\n",
      " \n",
      "\n",
      " _______________________Training Stage ends here______________________\n",
      "\n",
      "\n",
      "\n",
      "['10_013.png', '11_013.png', '01_0113013.PNG', '02_0203013.PNG', '04_0113013.PNG', '01_013.png', '02_0204013.PNG', '02_0113013.PNG', '03_013.png', '04_0203013.PNG', '05_013.png', '09_013.png', '03_0204013.PNG', '06_013.png', '12_013.png', '04_0204013.PNG', '01_0204013.PNG', '01_0203013.PNG', '03_0203013.PNG', '02_013.png', '08_013.png', '07_013.png', '04_013.png', '03_0113013.PNG']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf value: 0\n",
      "Accuracy : 0.5\n",
      "Precision: 0.5\n",
      "True positive rate : 0.0\n",
      "False positive rate: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf value: 0.5\n",
      "Accuracy : 0.5416666666666666\n",
      "Precision: 0.5555555555555556\n",
      "True positive rate : 0.4166666666666667\n",
      "False positive rate: 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf value: 1\n",
      "Accuracy : 0.5416666666666666\n",
      "Precision: 0.5333333333333333\n",
      "True positive rate : 0.6666666666666666\n",
      "False positive rate: 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf value: 1.5\n",
      "Accuracy : 0.5\n",
      "Precision: 0.5\n",
      "True positive rate : 1.0\n",
      "False positive rate: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf value: 2\n",
      "Accuracy : 0.5\n",
      "Precision: 0.5\n",
      "True positive rate : 1.0\n",
      "False positive rate: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf value: 2.5\n",
      "Accuracy : 0.5\n",
      "Precision: 0.5\n",
      "True positive rate : 1.0\n",
      "False positive rate: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf value: 3\n",
      "Accuracy : 0.5\n",
      "Precision: 0.5\n",
      "True positive rate : 1.0\n",
      "False positive rate: 1.0\n"
     ]
    }
   ],
   "source": [
    "def apply_FAST(source):\n",
    "    #here fast is only used for detecting the keypoints but later on BRIEF will be used for the \n",
    "    img = cv2.imread(source,0)     \n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    #kp1, des1 = orb.detectAndCompute(img1,None)\n",
    "    #kp2, des2 = orb.detectAndCompute(img2,None)   \n",
    "    # Initiate FAST extractor\n",
    "    fast = cv2.FastFeatureDetector_create()\n",
    "    kp = fast.detect(img,None)\n",
    "    # Initiate BRIEF extractor\n",
    "    brief = cv2.xfeatures2d.BriefDescriptorExtractor_create()\n",
    "    kp1, des1 = brief.compute(img, kp) \n",
    "    img = cv2.drawKeypoints(img,kp1,img)\n",
    "    cv2.imwrite(\"imageSIFT.jpg\",img)\n",
    "    return kp1, des1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def MATCH_CUSTOM(input1, input2):\n",
    "    name = input1.split(\"_\")\n",
    "    number_of_matches = 20;       \n",
    "    k1, d1 = apply_FAST(input1)\n",
    "    k2, d2 = apply_FAST(input2)\n",
    "    #print(\"Feature Lengths\", len(k1), len(k2))\n",
    "    # create BFMatcher object\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "    # Match descriptors.\n",
    "    #matches = bf.match(d1,d2)\n",
    "    matches = bf.knnMatch(d1,d2, k=2)\n",
    "    # Sort them in the order of their distance.\n",
    "    #matches = sorted(matches, key = lambda x:x.distance)\n",
    "    # Apply ratio test\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.60 * n.distance:\n",
    "            good.append([m])\n",
    "        \n",
    "    #print(\"Good Length: \", len(good))\n",
    "    #print(\"For entry \", name[0],\"between\", input1, \"and \", input2,\" Feature Lengths\", len(k1), len(k2), \"Maches : \", len(good))\n",
    "    return len(good)\n",
    "    #img1 = cv2.imread(input1,0)\n",
    "    #img2 = cv2.imread(input2,0)\n",
    "    #img3 = cv2.drawMatches(img1,k1,img2,k2, matches[:number_of_matches] ,None, flags=2)\n",
    "    #img3 = cv2.drawMatchesKnn(img1,k1,img2,k2,good,None, flags=2)\n",
    "    #plt.imshow(img3),plt.show()\n",
    "\n",
    "\n",
    "#Function to get the list of files in a supplied directory\n",
    "def files(path):  \n",
    "    for file in os.listdir(path):\n",
    "        if os.path.isfile(os.path.join(path, file)):\n",
    "            yield file\n",
    "\n",
    "\n",
    "\n",
    "                     \n",
    "print(sys.version)\n",
    "platform.python_version()\n",
    "PWD1 = \"050_Renfrenced\"\n",
    "entries = list()\n",
    "file_list = files(PWD1)\n",
    "for file in file_list:\n",
    "    if \"PNG\" in file:\n",
    "        #print(file)\n",
    "        entries.append(file)\n",
    "print(entries)\n",
    "\n",
    "\n",
    "\n",
    "#Training Stage\n",
    "match_values = list()\n",
    "number_of_entries = len(entries)\n",
    "data = list()\n",
    "for i in range(0, number_of_entries):\n",
    "    for j in range(i+1, number_of_entries):\n",
    "        #print(i, j)\n",
    "        match_values.append(MATCH_CUSTOM(PWD1 + \"/\" + entries[i],PWD1 + \"/\" +  entries[j]))\n",
    "        data.append([i,j,match_values[len(match_values)-1]])\n",
    "print(match_values)\n",
    "print(data)\n",
    "\n",
    "mean_ = int(sum(match_values)/len(match_values))\n",
    "std_dev = int(statistics.stdev(match_values))\n",
    "\n",
    "diff = -1;\n",
    "reference = None\n",
    "index = -5\n",
    "mean_new = -5\n",
    "for x in range(0, len(match_values)):\n",
    "    if match_values[x] > diff:\n",
    "        diff = match_values[x]\n",
    "        reference = entries[data[x][0]]\n",
    "        index = x       \n",
    "print(reference)\n",
    "print(str(mean_) + \"\\n \\n\\n _______________________Training Stage ends here______________________\\n\\n\\n\")\n",
    "\n",
    "#TestingStage\n",
    "PWD2 = \"050_Questioned\"\n",
    "entries = list()\n",
    "file_list = files(PWD2)\n",
    "for file in file_list:\n",
    "    if \"PNG\" in file:\n",
    "        #print(file)\n",
    "        #actual_class_false +=1\n",
    "        entries.append(file)\n",
    "    if \"png\" in file:\n",
    "        #print(file)\n",
    "        #actual_class_true +=1\n",
    "        entries.append(file)\n",
    "print(entries)\n",
    "\n",
    "threshold_factor = [0, 0.5, 1, 1.5, 2, 2.5, 3];\n",
    "\n",
    "for tf in threshold_factor:\n",
    "    #Confustion_Matrix_base\n",
    "    TP_true_positive  = 0\n",
    "    FN_false_negative = 0\n",
    "    FP_false_positive = 0\n",
    "    TN_true_negative  = 0\n",
    "    \n",
    "    for x in entries:\n",
    "        match_count = MATCH_CUSTOM(PWD2 + \"/\" + x ,PWD1 + \"/\" +  reference)\n",
    "        if len(x) == 10:\n",
    "            if abs(match_count-mean_) <= std_dev*tf:\n",
    "                TP_true_positive += 1\n",
    "            else:\n",
    "                FN_false_negative += 1\n",
    "        else:\n",
    "            if abs(match_count-mean_) <= std_dev*tf:\n",
    "                FP_false_positive +=1\n",
    "            else:\n",
    "                TN_true_negative +=1\n",
    "\n",
    "    #print(\"TP = \" + str(TP_true_positive) + \" FN = \" + str(FN_false_negative) )\n",
    "    #print(\"FP = \" + str(FP_false_positive) + \" TN = \" + str(TN_true_negative) )\n",
    "    TPR = TP_true_positive /(TP_true_positive + FN_false_negative)\n",
    "    FPR = FP_false_positive / (FP_false_positive + TN_true_negative)\n",
    "    accuracy = (TP_true_positive+ TN_true_negative)/24\n",
    "    if((TP_true_positive+FP_false_positive)!=0):\n",
    "        precision = TP_true_positive/(TP_true_positive+FP_false_positive)\n",
    "    recall = TP_true_positive / (TP_true_positive + FN_false_negative)\n",
    "    #f_measure = 2 / (1/precision+1/recall)\n",
    "    print(\"tf value: \" + str(tf))\n",
    "    print(\"Accuracy : \" + str ( accuracy))   \n",
    "    print(\"Precision: \" + str(precision))\n",
    "    #print(\"Recall   : \" + str(recall))\n",
    "    #print(\"F-measure: \" + str(f_measure))\n",
    "    print(\"True positive rate : \" + str(TPR))\n",
    "    print(\"False positive rate: \" + str(FPR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243073fb",
   "metadata": {},
   "source": [
    "# SVM Model SIFT Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22254b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imagehash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42681339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imagehash\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from pylab import *\n",
    "from PIL import Image\n",
    "from scipy.cluster.vq import *\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree, svm, linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1f240a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "genuine_images_path = \"/home/mehdi/Bureau/PI/data/genuine\"\n",
    "forged_images_path = \"/home/mehdi/Bureau/PI/data/forged\"\n",
    "\n",
    "genuine_image_filenames = listdir(genuine_images_path)\n",
    "forged_image_filenames = listdir(forged_images_path)\n",
    "\n",
    "genuine_image_features = [[] for x in range(12)]\n",
    "forged_image_features = [[] for x in range(12)]\n",
    "\n",
    "for name in genuine_image_filenames:\n",
    "    signature_id = int(name.split('_')[0][-3:])\n",
    "    genuine_image_features[signature_id - 1].append({\"name\": name})\n",
    "\n",
    "for name in forged_image_filenames:\n",
    "    signature_id = int(name.split('_')[0][-3:])\n",
    "    forged_image_features[signature_id - 1].append({\"name\": name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a4ef046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, display=False):\n",
    "    raw_image = cv2.imread(image_path)\n",
    "    bw_image = cv2.cvtColor(raw_image, cv2.COLOR_BGR2GRAY)\n",
    "    bw_image = 255 - bw_image\n",
    "    _, threshold_image = cv2.threshold(bw_image, 30, 255, 0)\n",
    "    return threshold_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abcb5bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contour_features(preprocessed_image, display=False):\n",
    "    \"\"\"\n",
    "    :param preprocessed_image: preprocessed image\n",
    "    :param display: flag - if true display images\n",
    "    :return: aspect ratio of bounding rectangle, area of bounding rectangle, contours and convex hull\n",
    "    \"\"\"\n",
    "\n",
    "    rect = cv2.minAreaRect(cv2.findNonZero(preprocessed_image))\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "\n",
    "    w = np.linalg.norm(box[0] - box[1])\n",
    "    h = np.linalg.norm(box[1] - box[2])\n",
    "\n",
    "    aspect_ratio = max(w, h) / min(w, h)\n",
    "    bounding_rect_area = w * h\n",
    "\n",
    "    if display:\n",
    "        image1 = cv2.drawContours(preprocessed_image.copy(), [box], 0, (120, 120, 120), 2)\n",
    "        \n",
    "\n",
    "    hull = cv2.convexHull(cv2.findNonZero(preprocessed_image))\n",
    "\n",
    "    if display:\n",
    "        convex_hull_image = cv2.drawContours(preprocessed_image.copy(), [hull], 0, (120, 120, 120), 2)\n",
    "        \n",
    "\n",
    "    contours, hierarchy = cv2.findContours(preprocessed_image.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if display:\n",
    "        contour_image = cv2.drawContours(preprocessed_image.copy(), contours, -1, (120, 120, 120), 3)\n",
    "       \n",
    "\n",
    "    contour_area = 0\n",
    "    for cnt in contours:\n",
    "        contour_area += cv2.contourArea(cnt)\n",
    "    hull_area = cv2.contourArea(hull)\n",
    "\n",
    "    return aspect_ratio, bounding_rect_area, hull_area, contour_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44cd961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sift(preprocessed_image, image_path, display=False):\n",
    "    raw_image = cv2.imread(image_path)\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    kp, des = sift.detectAndCompute(preprocessed_image, None)\n",
    "\n",
    "    if display:\n",
    "        cv2.drawKeypoints(preprocessed_image, kp, raw_image)\n",
    "\n",
    "\n",
    "    return (image_path, des)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7ca6b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "des_list = []\n",
    "true_positive = 0\n",
    "true_negative = 0\n",
    "false_positive = 0\n",
    "false_negative = 0\n",
    "\n",
    "im_contour_features = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9756c7",
   "metadata": {},
   "source": [
    "for i in range(2,10):\n",
    "    forged_images_path = \"/home/mehdi/Bureau/PI/PreprocessingFinal/signatures_preprocessing/forged_sign/\"+str(i)\n",
    "    x = os.path.join(forged_images_path,'*')\n",
    "    x = glob.glob(x)\n",
    "    for nameim in range(0,len(x)):\n",
    "        img = cv2.imread(x[nameim])\n",
    "        cv2.imwrite(\"/home/mehdi/Bureau/PI/PreprocessingFinal/signatures_preprocessing/forged_sign_final2/02100\"+str(i)+\"_00\"+str(nameim)+\".png\",img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "817053fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.86\n",
      "Precision:  0.93\n",
      "Recall:  0.78\n",
      "F1 score:  0.85\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    des_list = []\n",
    "    for im in genuine_image_features[i]:\n",
    "        \n",
    "        image_path = genuine_images_path + \"/\" + im['name']\n",
    "        preprocessed_image = preprocess_image(image_path)\n",
    "        hash = imagehash.phash(Image.open(image_path))\n",
    "\n",
    "        aspect_ratio, bounding_rect_area, convex_hull_area, contours_area = \\\n",
    "            get_contour_features(preprocessed_image.copy(), display=False)\n",
    "\n",
    "        hash = int(str(hash), 16)\n",
    "        im['hash'] = hash\n",
    "        im['aspect_ratio'] = aspect_ratio\n",
    "        im['hull_area/bounding_area'] = convex_hull_area / bounding_rect_area\n",
    "        im['contour_area/bounding_area'] = contours_area / bounding_rect_area\n",
    "\n",
    "        im_contour_features.append(\n",
    "            [hash, aspect_ratio, convex_hull_area / bounding_rect_area, contours_area / bounding_rect_area])\n",
    "\n",
    "        des_list.append(sift(preprocessed_image, image_path))\n",
    "\n",
    "    for im in forged_image_features[i]:\n",
    "        image_path = forged_images_path + \"/\" + im['name']\n",
    "        preprocessed_image = preprocess_image(image_path)\n",
    "        hash = imagehash.phash(Image.open(image_path))\n",
    "\n",
    "        aspect_ratio, bounding_rect_area, convex_hull_area, contours_area = \\\n",
    "            get_contour_features(preprocessed_image.copy(), display=False)\n",
    "\n",
    "        hash = int(str(hash), 16)\n",
    "        im['hash'] = hash\n",
    "        im['aspect_ratio'] = aspect_ratio\n",
    "        im['hull_area/bounding_area'] = convex_hull_area / bounding_rect_area\n",
    "        im['contour_area/bounding_area'] = contours_area / bounding_rect_area\n",
    "\n",
    "        im_contour_features.append(\n",
    "            [hash, aspect_ratio, convex_hull_area / bounding_rect_area, contours_area / bounding_rect_area])\n",
    "\n",
    "        des_list.append(sift(preprocessed_image, image_path))\n",
    "    \n",
    "    #print(des_list)\n",
    "    descriptors = des_list[0][1]\n",
    "    for image_path, descriptor in des_list[1:]:\n",
    "        descriptors = np.vstack((descriptors, descriptor))\n",
    "    k = 200\n",
    "    voc, variance = kmeans(descriptors, k, 1)\n",
    "\n",
    "    # Calculate the histogram of features\n",
    "    im_features = np.zeros((len(genuine_image_features[i]) + len(forged_image_features[i]), k + 4), \"float32\")\n",
    "    for i in range(len(genuine_image_features[i]) + len(forged_image_features[i])):\n",
    "        words, distance = vq(des_list[i][1], voc)\n",
    "        for w in words:\n",
    "            im_features[i][w] += 1\n",
    "\n",
    "        for j in range(4):\n",
    "            im_features[i][k + j] = im_contour_features[i][j]\n",
    "\n",
    "    # Scaling the words\n",
    "    stdSlr = StandardScaler().fit(im_features)\n",
    "    im_features = stdSlr.transform(im_features)\n",
    "\n",
    "    train_genuine_features, test_genuine_features = im_features[0:3], im_features[3:5]\n",
    "\n",
    "    train_forged_features, test_forged_features = im_features[5:8], im_features[8:10]\n",
    "\n",
    "    # clf = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "    clf = LinearSVC()\n",
    "    #clf = tree.DecisionTreeClassifier()\n",
    "    #clf = tree.DecisionTreeRegressor()\n",
    "    #clf = svm.SVC()\n",
    "\n",
    "    clf.fit(np.concatenate((train_forged_features, train_genuine_features)),\n",
    "            np.array([1 for x in range(len(train_forged_features))] + [2 for x in range(len(train_genuine_features))]))\n",
    "\n",
    "    genuine_res = clf.predict(test_genuine_features)\n",
    "\n",
    "    for res in genuine_res:\n",
    "        if int(res) == 2:\n",
    "            true_positive += 1\n",
    "        else:\n",
    "            false_negative += 1\n",
    "\n",
    "    forged_res = clf.predict(test_forged_features)\n",
    "\n",
    "    for res in forged_res:\n",
    "        if int(res) == 1:\n",
    "            true_negative += 1\n",
    "        else:\n",
    "            false_positive += 1\n",
    "\n",
    "accuracy = float(true_positive + true_negative) / (true_positive + true_negative + false_negative + false_positive)\n",
    "precision = float(true_positive) / (true_positive + false_positive)\n",
    "recall = float(true_positive) / (true_positive + false_negative)\n",
    "f1_score = float(2 * precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 2))\n",
    "print(\"Precision: \", round(precision, 2))\n",
    "print(\"Recall: \", round(recall, 2))\n",
    "print(\"F1 score: \", round(f1_score, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ab1e6b07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1140\n"
     ]
    }
   ],
   "source": [
    "print(len(im_contour_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c7d0c3",
   "metadata": {},
   "source": [
    "# Generating Forged Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a503f58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "#####################\n",
    "# Vertical wave\n",
    "\n",
    "def verticalImage(img,number):\n",
    "    rows, cols = img.shape\n",
    "    img_output = np.zeros(img.shape, dtype=img.dtype)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            offset_x = int(25.0 * math.sin(2 * 3.14 * i / 180))\n",
    "            offset_y = 0\n",
    "            if j+offset_x < rows:\n",
    "                img_output[i,j] = img[i,(j+offset_x)%cols]\n",
    "            else:\n",
    "                img_output[i,j] = 255\n",
    "    cv2.imwrite(\"/home/mehdi/Bureau/PI/PreprocessingFinal/signatures_preprocessing/forged_sign/\"+str(number)+\"/vertical.png\",img_output)            \n",
    "\n",
    "\n",
    "\n",
    "#####################\n",
    "# Horizontal wave\n",
    "def horizontalImage(img,number):\n",
    "    rows, cols = img.shape\n",
    "    img_output = np.zeros(img.shape, dtype=img.dtype)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            offset_x = 0\n",
    "            offset_y = int(16.0 * math.sin(2 * 3.14 * j / 150))\n",
    "            if i+offset_y < rows:\n",
    "                img_output[i,j] = img[(i+offset_y)%rows,j]\n",
    "            else:\n",
    "                img_output[i,j] = 255\n",
    "    cv2.imwrite(\"/home/mehdi/Bureau/PI/PreprocessingFinal/signatures_preprocessing/forged_sign/\"+str(number)+\"/horizontal.png\",img_output)            \n",
    "\n",
    "    \n",
    "#####################\n",
    "# Both horizontal and vertical \n",
    "def bothImage(img,number):\n",
    "    rows, cols = img.shape\n",
    "    img_output = np.zeros(img.shape, dtype=img.dtype)\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            offset_x = int(20.0 * math.sin(2 * 3.14 * i / 150))\n",
    "            offset_y = int(20.0 * math.cos(2 * 3.14 * j / 150))\n",
    "            if i+offset_y < rows and j+offset_x < cols:\n",
    "                img_output[i,j] = img[(i+offset_y)%rows,(j+offset_x)%cols]\n",
    "            else:\n",
    "                img_output[i,j] = 255\n",
    "    cv2.imwrite(\"/home/mehdi/Bureau/PI/PreprocessingFinal/signatures_preprocessing/forged_sign/\"+str(number)+\"/both.png\",img_output)            \n",
    "\n",
    "#####################\n",
    "# Concave effect\n",
    "def concaveImage(img,number):\n",
    "    rows, cols = img.shape\n",
    "    img_output = np.zeros(img.shape, dtype=img.dtype)\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            offset_x = int(128.0 * math.sin(2 * 3.14 * i / (2*cols)))\n",
    "            offset_y = 0\n",
    "            if j+offset_x < cols:\n",
    "                img_output[i,j] = img[i,(j+offset_x)%cols]\n",
    "            else:\n",
    "                img_output[i,j] = 255\n",
    "    cv2.imwrite(\"/home/mehdi/Bureau/PI/PreprocessingFinal/signatures_preprocessing/forged_sign/\"+str(number)+\"/concave.png\",img_output)            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da504ea5",
   "metadata": {},
   "source": [
    "## Creating Forged Sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20a16a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = cv2.imread(\"/home/mehdi/Bureau/PI/PreprocessingFinal/signatures_preprocessing/cleaned_sign/Cheque 309084.tif.png\")\n",
    "img1=cv2.resize(img1, (400,400), interpolation = cv2.INTER_AREA)\n",
    "imgray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(imgray, 127, 255, 0)\n",
    "#cv2.imwrite(\"/home/mehdi/Bureau/PI/PreprocessingFinal/signatures_preprocessing/th.png\",thresh)\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "imgg = cv2.drawContours(img1, contours, -1, (0,0,255), 3)\n",
    "#print(contours[0])\n",
    "for i in range(0,len(contours)):\n",
    "    j=0\n",
    "    for sc in contours[i]:\n",
    "        #print(\"Contour \", i , sc[0][0])\n",
    "        if (j%2 == 0):\n",
    "            sc[0][0] = sc[0][0] + 1\n",
    "            #sc[0][1] = sc[0][1] + 5\n",
    "        if (j%2 != 0):\n",
    "            sc[0][0] = sc[0][0] - 3\n",
    "            #sc[0][1] = sc[0][1] - 5\n",
    "        if (j%2 == 0):\n",
    "            #sc[0][0] = sc[0][0] + 1\n",
    "            sc[0][1] = sc[0][1] + 4\n",
    "        if (j%2 != 0):\n",
    "            #sc[0][0] = sc[0][0] - 1\n",
    "            sc[0][1] = sc[0][1] - 4    \n",
    "        j = j+1       \n",
    "bgr = np.zeros((imgg.shape[0], imgg.shape[1]), dtype= 'uint8')\n",
    "bgr = bgr+255\n",
    "cv2.drawContours(bgr, contours, -1, (0,0,0), 1)\n",
    "cv2.fillPoly(bgr, contours, color=(0,0,0))\n",
    "bgr = 255-bgr\n",
    "cv2.imwrite(\"/home/mehdi/Bureau/PI/PreprocessingFinal/signatures_preprocessing/imageT.png\",bgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b3b42b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createForged(imgName,i):\n",
    "    img = cv2.imread(\"/home/mehdi/Bureau/PI/PreprocessingFinal/signatures_preprocessing/cleaned_sign/\"+str(i)+\"/\"+imgName+\".png\", cv2.IMREAD_GRAYSCALE)\n",
    "    verticalImage(img,i)\n",
    "    horizontalImage(img,i)\n",
    "    bothImage(img,i)\n",
    "    concaveImage(img,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d75a97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating forged for our users\n",
    "createForged(\"Cheque 309135.tif\",1)\n",
    "createForged(\"Cheque 309061.tif\",2)\n",
    "createForged(\"Cheque 309129.tif\",3)\n",
    "createForged(\"Cheque 309070.tif\",4)\n",
    "createForged(\"Cheque 309089.tif\",5)\n",
    "createForged(\"Cheque 309103.tif\",6)\n",
    "createForged(\"Cheque 309105.tif\",7)\n",
    "createForged(\"Cheque 083654.tif\",8)\n",
    "createForged(\"Cheque 083658.tif\",9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e9d70b",
   "metadata": {},
   "source": [
    "### Loading our geniune and forged images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07c8f741",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "006006_009.png\n",
      "6\n",
      "009009_002.png\n",
      "9\n",
      "007007_008.png\n",
      "7\n",
      "001001_006.png\n",
      "1\n",
      "006006_007.png\n",
      "6\n",
      "009009_009.png\n",
      "9\n",
      "003003_008.png\n",
      "3\n",
      "001001_003.png\n",
      "1\n",
      "003003_005.png\n",
      "3\n",
      "003003_001.png\n",
      "3\n",
      "007007_002.png\n",
      "7\n",
      "004004_009.png\n",
      "4\n",
      "009009_010.png\n",
      "9\n",
      "007007_001.png\n",
      "7\n",
      "005005_007.png\n",
      "5\n",
      "009009_004.png\n",
      "9\n",
      "002002_002.png\n",
      "2\n",
      "008008_006.png\n",
      "8\n",
      "006006_002.png\n",
      "6\n",
      "009009_000.png\n",
      "9\n",
      "002002_003.png\n",
      "2\n",
      "008008_009.png\n",
      "8\n",
      "004004_007.png\n",
      "4\n",
      "007007_013.png\n",
      "7\n",
      "003003_002.png\n",
      "3\n",
      "007007_003.png\n",
      "7\n",
      "009009_006.png\n",
      "9\n",
      "001001_002.png\n",
      "1\n",
      "007007_011.png\n",
      "7\n",
      "008008_000.png\n",
      "8\n",
      "007007_006.png\n",
      "7\n",
      "001001_005.png\n",
      "1\n",
      "003003_003.png\n",
      "3\n",
      "005005_002.png\n",
      "5\n",
      "006006_013.png\n",
      "6\n",
      "006006_003.png\n",
      "6\n",
      "007007_009.png\n",
      "7\n",
      "009009_001.png\n",
      "9\n",
      "003003_009.png\n",
      "3\n",
      "006006_012.png\n",
      "6\n",
      "003003_000.png\n",
      "3\n",
      "002002_001.png\n",
      "2\n",
      "001001_009.png\n",
      "1\n",
      "006006_010.png\n",
      "6\n",
      "002002_008.png\n",
      "2\n",
      "003003_004.png\n",
      "3\n",
      "005005_000.png\n",
      "5\n",
      "007007_000.png\n",
      "7\n",
      "009009_008.png\n",
      "9\n",
      "002002_011.png\n",
      "2\n",
      "007007_005.png\n",
      "7\n",
      "006006_008.png\n",
      "6\n",
      "001001_004.png\n",
      "1\n",
      "007007_012.png\n",
      "7\n",
      "008008_011.png\n",
      "8\n",
      "008008_008.png\n",
      "8\n",
      "008008_007.png\n",
      "8\n",
      "001001_001.png\n",
      "1\n",
      "004004_000.png\n",
      "4\n",
      "008008_012.png\n",
      "8\n",
      "004004_002.png\n",
      "4\n",
      "008008_005.png\n",
      "8\n",
      "008008_001.png\n",
      "8\n",
      "005005_003.png\n",
      "5\n",
      "002002_009.png\n",
      "2\n",
      "008008_003.png\n",
      "8\n",
      "004004_010.png\n",
      "4\n",
      "005005_009.png\n",
      "5\n",
      "003003_007.png\n",
      "3\n",
      "006006_005.png\n",
      "6\n",
      "004004_004.png\n",
      "4\n",
      "003003_006.png\n",
      "3\n",
      "009009_011.png\n",
      "9\n",
      "005005_008.png\n",
      "5\n",
      "006006_006.png\n",
      "6\n",
      "006006_004.png\n",
      "6\n",
      "003003_010.png\n",
      "3\n",
      "002002_005.png\n",
      "2\n",
      "004004_008.png\n",
      "4\n",
      "005005_005.png\n",
      "5\n",
      "006006_000.png\n",
      "6\n",
      "009009_012.png\n",
      "9\n",
      "008008_010.png\n",
      "8\n",
      "001001_007.png\n",
      "1\n",
      "004004_003.png\n",
      "4\n",
      "006006_001.png\n",
      "6\n",
      "002002_000.png\n",
      "2\n",
      "008008_002.png\n",
      "8\n",
      "002002_006.png\n",
      "2\n",
      "003003_011.png\n",
      "3\n",
      "001001_008.png\n",
      "1\n",
      "001001_010.png\n",
      "1\n",
      "009009_005.png\n",
      "9\n",
      "007007_007.png\n",
      "7\n",
      "002002_007.png\n",
      "2\n",
      "005005_004.png\n",
      "5\n",
      "009009_007.png\n",
      "9\n",
      "005005_001.png\n",
      "5\n",
      "004004_005.png\n",
      "4\n",
      "008008_004.png\n",
      "8\n",
      "006006_011.png\n",
      "6\n",
      "007007_010.png\n",
      "7\n",
      "007007_004.png\n",
      "7\n",
      "004004_006.png\n",
      "4\n",
      "004004_001.png\n",
      "4\n",
      "002002_010.png\n",
      "2\n",
      "003003_012.png\n",
      "3\n",
      "005005_006.png\n",
      "5\n",
      "001001_000.png\n",
      "1\n",
      "009009_003.png\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "genuine_images_path = \"/home/mehdi/Bureau/PI/PreprocessingFinal/signatures_preprocessing/cleaned_sign_final2\"\n",
    "forged_images_path = \"/home/mehdi/Bureau/PI/PreprocessingFinal/signatures_preprocessing/forged_sign_final\"\n",
    "\n",
    "genuine_image_filenames = listdir(genuine_images_path)\n",
    "forged_image_filenames = listdir(forged_images_path)\n",
    "\n",
    "genuine_image_features = [[] for x in range(9)]\n",
    "forged_image_features = [[] for x in range(9)]\n",
    "\n",
    "for name in genuine_image_filenames:\n",
    "    print(name)\n",
    "    signature_id = int(name.split('_')[0][-3:])\n",
    "    print(signature_id)\n",
    "    genuine_image_features[signature_id - 1].append({\"name\": name})\n",
    "\n",
    "for name in forged_image_filenames:\n",
    "    signature_id = int(name.split('_')[0][-3:])\n",
    "    forged_image_features[signature_id - 1].append({\"name\": name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71a6cbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, display=False):\n",
    "    raw_image = cv2.imread(image_path)\n",
    "    bw_image = cv2.cvtColor(raw_image, cv2.COLOR_BGR2GRAY)\n",
    "    bw_image = 255 - bw_image\n",
    "    _, threshold_image = cv2.threshold(bw_image, 30, 255, 0)\n",
    "    return threshold_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f22b004",
   "metadata": {},
   "source": [
    "# SIFT and SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb18a92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehdi/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.75\n",
      "Precision:  0.83\n",
      "Recall:  0.85\n",
      "F1 score:  0.84\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,9):\n",
    "    z=i\n",
    "    if i == 3:\n",
    "        continue\n",
    "    des_list = []\n",
    "    for im in genuine_image_features[i]:\n",
    "        \n",
    "        image_path = genuine_images_path + \"/\" + im['name']\n",
    "        #1\n",
    "        preprocessed_image = preprocess_image(image_path)\n",
    "        #2\n",
    "        hash = imagehash.phash(Image.open(image_path))\n",
    "\n",
    "        #3\n",
    "        aspect_ratio, bounding_rect_area, convex_hull_area, contours_area = \\\n",
    "            get_contour_features(preprocessed_image.copy(), display=False)\n",
    "\n",
    "        hash = int(str(hash), 16)\n",
    "        im['hash'] = hash\n",
    "        im['aspect_ratio'] = aspect_ratio\n",
    "        im['hull_area/bounding_area'] = convex_hull_area / bounding_rect_area\n",
    "        im['contour_area/bounding_area'] = contours_area / bounding_rect_area\n",
    "\n",
    "        im_contour_features.append(\n",
    "            [hash, aspect_ratio, convex_hull_area / bounding_rect_area, contours_area / bounding_rect_area])\n",
    "\n",
    "        des_list.append(sift(preprocessed_image, image_path))\n",
    "\n",
    "    for im in forged_image_features[i]:\n",
    "        image_path = forged_images_path + \"/\" + im['name']\n",
    "        preprocessed_image = preprocess_image(image_path)\n",
    "        hash = imagehash.phash(Image.open(image_path))\n",
    "\n",
    "        aspect_ratio, bounding_rect_area, convex_hull_area, contours_area = \\\n",
    "            get_contour_features(preprocessed_image.copy(), display=False)\n",
    "\n",
    "        hash = int(str(hash), 16)\n",
    "        im['hash'] = hash\n",
    "        im['aspect_ratio'] = aspect_ratio\n",
    "        im['hull_area/bounding_area'] = convex_hull_area / bounding_rect_area\n",
    "        im['contour_area/bounding_area'] = contours_area / bounding_rect_area\n",
    "\n",
    "        im_contour_features.append(\n",
    "            [hash, aspect_ratio, convex_hull_area / bounding_rect_area, contours_area / bounding_rect_area])\n",
    "\n",
    "        des_list.append(sift(preprocessed_image, image_path))\n",
    "    \n",
    "    #print(des_list)\n",
    "    descriptors = des_list[0][1]\n",
    "    for image_path, descriptor in des_list[1:]:\n",
    "        descriptors = np.vstack((descriptors, descriptor))\n",
    "    k = 200\n",
    "    voc, variance = kmeans(descriptors, k, 1)\n",
    "\n",
    "    # Calculate the histogram of features\n",
    "    im_features = np.zeros((len(genuine_image_features[i]) + len(forged_image_features[i]), k + 4), \"float32\")\n",
    "    \n",
    "    for i in range(len(genuine_image_features[i]) + len(forged_image_features[i])):\n",
    "        words, distance = vq(des_list[i][1], voc)\n",
    "        for w in words:\n",
    "            im_features[i][w] += 1\n",
    "\n",
    "        for j in range(4):\n",
    "            im_features[i][k + j] = im_contour_features[i][j]\n",
    "\n",
    "    # Scaling the words\n",
    "    stdSlr = StandardScaler().fit(im_features)\n",
    "    im_features = stdSlr.transform(im_features)\n",
    "\n",
    "    train_genuine_features, test_genuine_features = im_features[0:len(im_features)-8], im_features[len(im_features)-8:len(im_features)-4]\n",
    "\n",
    "    train_forged_features, test_forged_features = im_features[len(im_features)-4:len(im_features)-1], im_features[len(im_features)-1:len(im_features)]\n",
    "\n",
    "    # clf = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "    clf = LinearSVC(penalty=\"l1\",loss='squared_hinge', dual=False)\n",
    "    #clf = tree.DecisionTreeClassifier()\n",
    "    #clf = tree.DecisionTreeRegressor()\n",
    "    #clf = svm.SVC()\n",
    "    clf.fit(np.concatenate((train_forged_features, train_genuine_features)),\n",
    "            np.array([1 for x in range(len(train_forged_features))] + [2 for x in range(len(train_genuine_features))]))\n",
    "\n",
    "    genuine_res = clf.predict(test_genuine_features)\n",
    "    for res in genuine_res:\n",
    "        if int(res) == 2:\n",
    "            true_positive += 1\n",
    "        else:\n",
    "            false_negative += 1\n",
    "\n",
    "    forged_res = clf.predict(test_forged_features)\n",
    "\n",
    "    for res in forged_res:\n",
    "        if int(res) == 1:\n",
    "            true_negative += 1\n",
    "        else:\n",
    "            false_positive += 1\n",
    "    \n",
    "    pickle.dump(clf,open(\"/home/mehdi/Bureau/PI/ModelUser/model\"+str(z)+\".pkl\",\"wb\"))\n",
    "accuracy = float(true_positive + true_negative) / (true_positive + true_negative + false_negative + false_positive)\n",
    "precision = float(true_positive) / (true_positive + false_positive)\n",
    "recall = float(true_positive) / (true_positive + false_negative)\n",
    "f1_score = float(2 * precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy, 2))\n",
    "print(\"Precision: \", round(precision, 2))\n",
    "print(\"Recall: \", round(recall, 2))\n",
    "print(\"F1 score: \", round(f1_score, 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "99d63bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.5491934  -0.25       -0.25       -0.51571065 -0.25       -0.25\n",
      "  -0.36514837  0.9805807  -0.46291006 -0.25       -0.3441236  -0.46291006\n",
      "  -0.25       -0.6         1.5491934  -0.46291006  2.9911215  -0.46291006\n",
      "  -0.3651484  -0.5547002   0.62403774 -0.4313311  -0.46291006 -0.51571065\n",
      "  -0.46291006 -0.6        -0.25       -0.42215854 -0.46291006 -0.5547002\n",
      "  -0.57854193  2.1602468  -0.36514837  1.401826   -0.36514837 -0.5547002\n",
      "  -0.64549726  1.1        -0.36514837 -0.36514837 -0.36514837  0.51425946\n",
      "  -0.36514837 -0.36514837 -0.36514837 -0.36514837 -0.36514837 -0.25\n",
      "  -0.25        2.6465385  -0.64549726  2.738613    1.8027756   2.1602468\n",
      "  -0.25       -0.3928371  -0.5547002  -0.3441236  -0.3441236   2.738613\n",
      "  -0.3441236  -0.25       -0.36514837 -0.36514837 -0.36514837 -0.6761234\n",
      "  -0.73854893 -0.3223292  -0.46291006 -0.51571065 -0.3441236  -0.5547002\n",
      "   2.738613   -0.36514837 -0.5547002  -0.25       -0.36514837 -0.25\n",
      "  -0.36514837 -0.5547002   1.1         0.6761234  -0.5547002  -0.25\n",
      "  -0.46291006  2.738613   -0.46291006 -0.25        0.9805807   1.8027756\n",
      "   2.1602468   1.1        -0.44194177  1.5491934  -0.25       -0.3441236\n",
      "   0.85125655 -0.36514837 -0.5547002  -0.36514837  1.401826   -0.25\n",
      "  -0.5547002  -0.25       -0.36514837  1.401826   -0.36514837  2.1602468\n",
      "  -0.36514837 -0.36514837 -0.4313311  -0.3223292   2.738613   -0.5547002\n",
      "   2.1128857  -0.25       -0.25       -0.36514837 -0.25       -0.25\n",
      "  -0.3441236  -0.5547002  -0.64549726 -0.36514837  1.6059102  -0.36514837\n",
      "  -0.25       -0.5547002  -0.25       -0.3441236   1.8027756  -0.36514837\n",
      "  -0.25       -0.51571065 -0.3441236  -0.4313311  -0.25        2.738613\n",
      "  -0.36514837 -0.25       -0.46291006 -0.3441236   2.1602468   2.738613\n",
      "  -0.5183211  -0.3441236   2.1602468   1.401826   -0.3441236   0.14708711\n",
      "   3.5559437  -0.25       -0.36514837 -0.36514837 -0.46291006 -0.25\n",
      "  -0.25        1.1        -0.25        0.84866846 -0.25       -0.25\n",
      "  -0.46291006 -0.36514837 -0.46291006 -0.36514837  2.738613   -0.51571065\n",
      "  -0.36514837  1.3540064  -0.36514837 -0.25       -0.36514837 -0.3223292\n",
      "  -0.25       -0.25        2.738613   -0.46291006 -0.6864065  -0.51571065\n",
      "  -0.46291006 -0.25       -0.3223292  -0.25        1.5491934  -0.46291006\n",
      "  -0.25        2.9911215   3.877382   -0.51571065  0.7624929  -0.25\n",
      "  -0.4313311  -0.436648   -0.25       -0.36514837 -0.5547002   4.\n",
      "  -0.36514837 -0.36514837  0.17468987  1.9068205   0.12256838 -0.6212597 ]]\n"
     ]
    }
   ],
   "source": [
    "print(test_forged_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d478c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(test_forged_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2a45945",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf,open(\"model.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7901f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07d450c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
